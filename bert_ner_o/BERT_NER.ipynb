{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_NER.ipynb","provenance":[],"collapsed_sections":["N7K1jxPJae5V"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eLOABUYE5JTI","colab_type":"text"},"source":["# connect to drive\n"]},{"cell_type":"code","metadata":{"id":"Avt-E4sGPdTd","colab_type":"code","outputId":"4eda4c93-f4cb-4411-9521-0a76fff0dd3a","executionInfo":{"status":"ok","timestamp":1574378674650,"user_tz":-480,"elapsed":69000,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","os.chdir(\"/\")\n","\n","from google.colab import drive\n","try:\n","    drive.mount('content/gdrive', force_remount=True)\n","except:\n","    print('你的 drive 掛載不成功')\n","    \n","os.chdir(\"/content/gdrive/My Drive/\")\n","\n","files = []\n","for r, d, f in os.walk(\"/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/\"):\n","    for file in f:\n","        \n","        files.append(os.path.join(r, file))\n","\n","for f in files:\n","    print(f)\n","    \n","os.chdir(\"/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/\")\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at content/gdrive\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/optimization.py\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/tokenization.py\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/BERT_NER.py\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/tf_metrics.py\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/run.sh\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/README.md\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/test.png\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/vocab.txt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/conlleval.pl\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/unittest.ipynb\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/BERT_NER.ipynb\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/base_model/.DS_Store\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/base_model/chinese-wwm_L-12_H-768_A-12/bert_model.ckpt.meta\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/base_model/chinese-wwm_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/base_model/chinese-wwm_L-12_H-768_A-12/vocab.txt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/base_model/chinese-wwm_L-12_H-768_A-12/bert_model.ckpt.index\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/base_model/chinese-wwm_L-12_H-768_A-12/bert_config.json\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/data/for_dev_and_test.txt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/data/for_train.txt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/modeling.cpython-37.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/tokenization.cpython-37.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/tf_metrics.cpython-37.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/optimization.cpython-37.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/modeling.cpython-36.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/optimization.cpython-36.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/tokenization.cpython-36.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/__pycache__/tf_metrics.cpython-36.pyc\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/events.out.tfevents.1574350334.a8e299d4e707\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/train.tf_record\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/graph.pbtxt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-10000.data-00000-of-00001\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-10000.index\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-10000.meta\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-11000.data-00000-of-00001\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-11000.index\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-11000.meta\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-12000.data-00000-of-00001\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-12000.index\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-12000.meta\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-13000.data-00000-of-00001\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-13000.index\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-13000.meta\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-13040.index\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-13040.meta\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/eval.tf_record\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/checkpoint\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/model.ckpt-13040.data-00000-of-00001\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/eval_results.txt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/predict.tf_record\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/token_test.txt\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/label_test.csv\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/label2id.pkl\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/test_samples_results.csv\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/test_samples_results.gsheet\n","/content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/output/eval/events.out.tfevents.1574353437.a8e299d4e707\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"csdIWPbOVVrq","colab_type":"code","outputId":"cc7176bf-fbed-4954-e944-1cb320c0ddee","executionInfo":{"status":"ok","timestamp":1571645582701,"user_tz":-480,"elapsed":3468,"user":{"displayName":"神邏輯哈哈","photoUrl":"","userId":"09623568965022025632"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!python BERT_NER.py \\\n","    --do_train=True \\\n","\t  --do_eval=True \\\n","\t  --do_predict=True \\\n","    --data_dir=data/ \\\n","    --bert_config_file=base_model/chinese-wwm_L-12_H-768_A-12/bert_config.json \\\n","    --init_checkpoint=base_model/chinese-wwm_L-12_H-768_A-12/bert_model.ckpt \\\n","    --vocab_file=base_model/chinese-wwm_L-12_H-768_A-12/vocab.txt \\\n","    --output_dir=./output/ \\\n","    --num_labels=11 \\\n","    --tags=\\[\\\"o\\\",\\\"B-CHA\\\",\\\"I-CHA\\\",\\\"B-TIM\\\",\\\"I-TIM\\\",\\\"B-MON\\\",\\\"I-MON\\\",\\\"B-PER\\\",\\\"I-PER\\\",\\\"[CLS]\\\",\\\"[SEP]\\\"]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["python3: can't open file 'BERT_NER.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K3aXbzeP50zU","colab_type":"text"},"source":["# Main"]},{"cell_type":"code","metadata":{"id":"mrzJ7CfE9Glg","colab_type":"code","outputId":"9fe525b0-fd7e-4665-e0a1-bdd9f8e14826","executionInfo":{"status":"ok","timestamp":1574353464246,"user_tz":-480,"elapsed":2966171,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wL1yPlQeascV-g99V0P-BZpxRCFljRM3"}},"source":["#! usr/bin/env python3\n","# -*- coding:utf-8 -*-\n","\"\"\"\n","Copyright 2018 The Google AI Language Team Authors.\n","BASED ON Google_BERT.\n","@Author:zhoukaiyin\n","Adjust code for chinese ner\n","\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import collections\n","import os\n","import modeling\n","import optimization\n","import tokenization\n","import tensorflow as tf\n","from sklearn.metrics import f1_score,precision_score,recall_score\n","from tensorflow.python.ops import math_ops\n","import tf_metrics\n","import pickle\n","import json\n","import os\n","from kashgari.corpus import ChineseDailyNerCorpus\n","\n","\n","\n","\n","\n","traindata_dir = 'data/'\n","bert_config_file = 'base_model/chinese-wwm_L-12_H-768_A-12/bert_config.json'\n","task_name = \"kashgari\"\n","output_dir = './output/'\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","init_checkpoint = 'base_model/chinese-wwm_L-12_H-768_A-12/bert_model.ckpt'\n","do_lower_case = True\n","max_seq_length =128\n","use_tpu = False\n","do_train = True\n","do_eval = True\n","do_predict = True\n","train_batch_size = 8\n","eval_batch_size = 8\n","predict_batch_size = 8\n","learning_rate = 5e-5\n","num_train_epochs = 5.0\n","warmup_proportion = 0.1\n","save_checkpoints_steps = 1000\n","iterations_per_loop = 1000\n","vocab_file = './base_model/chinese-wwm_L-12_H-768_A-12/vocab.txt'\n","master = None\n","num_tpu_cores = 8\n","crf_loss_method=True\n","\n","\n","\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text, label=None):\n","        \"\"\"Constructs a InputExample.\n","\n","        Args:\n","          guid: Unique id for the example.\n","          text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","          label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text = text\n","        self.label = label\n","\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_ids,):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_ids = label_ids\n","        #self.label_mask = label_mask\n","\n","\n","class DataProcessor(object):\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()\n","\n","    @classmethod\n","    def _read_data(cls, input_file):\n","        \"\"\"Reads a BIO data.\"\"\"\n","        with open(input_file) as f:\n","            lines = []\n","            words = []\n","            labels = []\n","            for line in f:\n","                contends = line.strip()\n","                word = line.strip().split(' ')[0]\n","                label = line.strip().split(' ')[-1]\n","                if contends.startswith(\"-DOCSTART-\"):\n","                    words.append('')\n","                    continue\n","                # if len(contends) == 0 and words[-1] == '。':\n","                if len(contends) == 0:\n","                    l = ' '.join([label for label in labels if len(label) > 0])\n","                    w = ' '.join([word for word in words if len(word) > 0])\n","                    lines.append([l, w])\n","                    words = []\n","                    labels = []\n","                    continue\n","                words.append(word)\n","                labels.append(label)\n","            return lines\n","\n","\n","class NerProcessor(DataProcessor):\n","    def get_train_examples(self, data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_train.txt\")), \"train\"\n","        )\n","\n","    def get_dev_examples(self, data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_dev_and_test.txt\")), \"dev\"\n","        )\n","\n","    def get_test_examples(self,data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_dev_and_test.txt\")), \"test\")\n","\n","\n","    def get_labels(self):\n","        # prevent potential bug for chinese text mixed with english text\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\",\"[SEP]\"]\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"X\",\"[CLS]\",\"[SEP]\"]\n","        global traindata_dir\n","        examples = self.get_train_examples(traindata_dir)\n","        tags = [\"[CLS]\",\"[SEP]\"]\n","        for e in examples:\n","            \n","            for l in e.label.split(\" \"):\n","                if l not in tags:\n","                  tags.append(l)\n","        return tags\n","        #return [\"o\", \"B-CHA\", \"I-CHA\", \"B-TIM\", \"I-TIM\", \"B-MON\", \"I-MON\", \"B-PER\", \"I-PER\",\"[CLS]\",\"[SEP]\"]\n","\n","    def _create_example(self, lines, set_type):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text = tokenization.convert_to_unicode(line[1])\n","            label = tokenization.convert_to_unicode(line[0])\n","            examples.append(InputExample(guid=guid, text=text, label=label))\n","        return examples\n","\n","\n","\n","class kashgariProcessor(DataProcessor):\n","    \"\"\"\n","    from kashgari.corpus import ChineseDailyNerCorpus\n","\n","    train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","    valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","    test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","    \"\"\"\n","    \n","    def get_train_examples(self,*args):\n","        train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","         \n","        return self._create_example(self.load_data2set(train_x, train_y), \"train\")\n","\n","    def get_dev_examples(self,*args):\n","        valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","        return self._create_example(self.load_data2set(valid_x, valid_y, max_num = 1000), \"dev\")\n","\n","    def get_test_examples(self,*args):\n","        test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","        return self._create_example(self.load_data2set(test_x, test_y, max_num = 1000), \"test\")\n","\n","\n","    def load_data2set(self,set_x, set_y, max_num = 50000):\n","      \n","      data_set = []\n","      idx = 0\n","      sent_text,sent_slot=\"\",\"\"\n","      for label,ans in zip(set_x,set_y):\n","          idx+=1\n","          if idx > max_num and max_num !=-1:\n","            break\n","          sent_text = \" \".join(label)\n","          sent_slot = \" \".join(ans)\n","          data_set.append([sent_text,sent_slot])\n","          \n","      return data_set\n","    def get_labels(self):\n","        # prevent potential bug for chinese text mixed with english text\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\",\"[SEP]\"]\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"X\",\"[CLS]\",\"[SEP]\"]\n","        \n","        examples = self.get_train_examples()\n","        tags = [\"[CLS]\",\"[SEP]\"]\n","        \n","        for idx,e in enumerate(examples):\n","            temp_tags = e.label.split(\" \")\n","            for n_tag in temp_tags:\n","              if n_tag not in tags:\n","                tags.append(n_tag)\n","        return tags\n","\n","    def _create_example(self, lines, set_type):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text = tokenization.convert_to_unicode(line[0])\n","            label = tokenization.convert_to_unicode(line[1])\n","            examples.append(InputExample(guid=guid, text=text, label=label))\n","        return examples\n","def write_tokens(tokens,mode):\n","    if mode==\"test\":\n","        path = os.path.join(output_dir, \"token_\"+mode+\".txt\")\n","        wf = open(path,'a')\n","        for token in tokens:\n","            if token!=\"**NULL**\":\n","                wf.write(token+'\\n')\n","        wf.close()\n","\n","def convert_single_example(ex_index, example, label_map, max_seq_length, tokenizer,mode):\n","    textlist = example.text.split(' ')\n","    labellist = example.label.split(' ')\n","    tokens = []\n","    labels = []\n","    # print(textlist)\n","    for i, word in enumerate(textlist):\n","        token = tokenizer.tokenize(word)\n","        # print(token)\n","        tokens.extend(token)\n","        label_1 = labellist[i]\n","        # print(label_1)\n","        for m in range(len(token)):\n","            if m == 0:\n","                labels.append(label_1)\n","            else:\n","                labels.append(\"X\")\n","        # print(tokens, labels)\n","    # tokens = tokenizer.tokenize(example.text)\n","    if len(tokens) >= max_seq_length - 1:\n","        tokens = tokens[0:(max_seq_length - 2)]\n","        labels = labels[0:(max_seq_length - 2)]\n","    ntokens = []\n","    segment_ids = []\n","    label_ids = []\n","    ntokens.append(\"[CLS]\")\n","    segment_ids.append(0)\n","    # append(\"O\") or append(\"[CLS]\") not sure!\n","    label_ids.append(label_map[\"[CLS]\"])\n","    for i, token in enumerate(tokens):\n","        ntokens.append(token)\n","        segment_ids.append(0)\n","        label_ids.append(label_map[labels[i]])\n","    ntokens.append(\"[SEP]\")\n","    segment_ids.append(0)\n","    # append(\"O\") or append(\"[SEP]\") not sure!\n","    label_ids.append(label_map[\"[SEP]\"])\n","    input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n","    input_mask = [1] * len(input_ids)\n","    #label_mask = [1] * len(input_ids)\n","    while len(input_ids) < max_seq_length:\n","        input_ids.append(0)\n","        input_mask.append(0)\n","        segment_ids.append(0)\n","        # we don't concerned about it!\n","        label_ids.append(0)\n","        ntokens.append(\"**NULL**\")\n","        #label_mask.append(0)\n","    # print(len(input_ids))\n","    assert len(input_ids) == max_seq_length\n","    assert len(input_mask) == max_seq_length\n","    assert len(segment_ids) == max_seq_length\n","    assert len(label_ids) == max_seq_length\n","    #assert len(label_mask) == max_seq_length\n","\n","    if ex_index < 5:\n","        tf.logging.info(\"*** Example ***\")\n","        tf.logging.info(\"guid: %s\" % (example.guid))\n","        tf.logging.info(\"tokens: %s\" % \" \".join(\n","            [tokenization.printable_text(x) for x in tokens]))\n","        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n","        tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n","        tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n","        tf.logging.info(\"label_ids: %s\" % \" \".join([str(x) for x in label_ids]))\n","        #tf.logging.info(\"label_mask: %s\" % \" \".join([str(x) for x in label_mask]))\n","\n","    feature = InputFeatures(\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        segment_ids=segment_ids,\n","        label_ids=label_ids,\n","        #label_mask = label_mask\n","    )\n","    write_tokens(ntokens,mode)\n","    return feature\n","\n","\n","def filed_based_convert_examples_to_features(\n","        examples, label_list, max_seq_length, tokenizer, output_file,mode=None\n","):\n","    label_map = {}\n","    for (i, label) in enumerate(label_list,1):\n","        label_map[label] = i\n","    ###\n","    with open('./output/label2id.pkl','wb') as w:\n","        pickle.dump(label_map,w)\n","\n","    writer = tf.python_io.TFRecordWriter(output_file)\n","    for (ex_index, example) in enumerate(examples):\n","        if ex_index % 5000 == 0:\n","            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n","        feature = convert_single_example(ex_index, example, label_map, max_seq_length, tokenizer,mode)\n","        \n","        def create_int_feature(values):\n","            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n","            return f\n","\n","        features = collections.OrderedDict()\n","        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n","        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n","        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n","        features[\"label_ids\"] = create_int_feature(feature.label_ids)\n","        #features[\"label_mask\"] = create_int_feature(feature.label_mask)\n","        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n","        writer.write(tf_example.SerializeToString())\n","\n","\n","def file_based_input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n","\n","    name_to_features = {\n","        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n","        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","        \"label_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","        # \"label_ids\":tf.VarLenFeature(tf.int64),\n","        #\"label_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n","    }\n","\n","    def _decode_record(record, name_to_features):\n","        example = tf.parse_single_example(record, name_to_features)\n","        for name in list(example.keys()):\n","            t = example[name]\n","            if t.dtype == tf.int64:\n","                t = tf.to_int32(t)\n","            example[name] = t\n","        return example\n","\n","    def input_fn(params):\n","        batch_size = params[\"batch_size\"]\n","        d = tf.data.TFRecordDataset(input_file)\n","        if is_training:\n","            d = d.repeat()\n","            d = d.shuffle(buffer_size=100)\n","        d = d.apply(tf.contrib.data.map_and_batch(\n","            lambda record: _decode_record(record, name_to_features),\n","            batch_size=batch_size,\n","            drop_remainder=drop_remainder\n","        ))\n","        return d\n","\n","    return input_fn\n","\n","\n","def create_model(bert_config, is_training, input_ids, input_mask,\n","                 segment_ids, labels, num_labels, use_one_hot_embeddings):\n","    model = modeling.BertModel(\n","        config=bert_config,\n","        is_training=is_training,\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        token_type_ids=segment_ids,\n","        use_one_hot_embeddings=use_one_hot_embeddings\n","    )\n","\n","    output_layer = model.get_sequence_output()\n","\n","    hidden_size = output_layer.shape[-1].value\n","\n","    output_weight = tf.get_variable(\n","        \"output_weights\", [num_labels, hidden_size],\n","        initializer=tf.truncated_normal_initializer(stddev=0.02)\n","    )\n","    output_bias = tf.get_variable(\n","        \"output_bias\", [num_labels], initializer=tf.zeros_initializer()\n","    )\n","    with tf.variable_scope(\"loss\"):\n","        global crf_loss_method\n","        if crf_loss_method is False:\n","            if is_training:\n","                output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","            output_layer = tf.reshape(output_layer, [-1, hidden_size])\n","            logits = tf.matmul(output_layer, output_weight, transpose_b=True)\n","            logits = tf.nn.bias_add(logits, output_bias)\n","            logits = tf.reshape(logits, [-1, max_seq_length, num_labels])\n","            # mask = tf.cast(input_mask,tf.float32)\n","            # loss = tf.contrib.seq2seq.sequence_loss(logits,labels,mask)\n","            # return (loss, logits, predict)\n","            ##########################################################################\n","            log_probs = tf.nn.log_softmax(logits, axis=-1)\n","            one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","            per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","            loss = tf.reduce_sum(per_example_loss)\n","            probabilities = tf.nn.softmax(logits, axis=-1)\n","            predict = tf.argmax(probabilities,axis=-1)\n","            \n","            ##########################################################################\n","        else:\n","            logits = tf.layers.dense(\n","                inputs=output_layer,\n","                units=num_labels,\n","                use_bias=True,\n","                bias_initializer=tf.zeros_initializer(),\n","                # kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n","                kernel_initializer=tf.contrib.layers.xavier_initializer()\n","            )\n","            mask_length = tf.reduce_sum(input_mask, axis=1)\n","\n","            log_likelihood, transition = tf.contrib.crf.crf_log_likelihood(\n","                inputs=logits,\n","                tag_indices=labels,\n","                sequence_lengths=mask_length)\n","\n","            decode_tags, best_score =  tf.contrib.crf.crf_decode(\n","                potentials=logits,\n","                transition_params=transition,\n","                sequence_length=mask_length)\n","\n","            predict = tf.identity(decode_tags, name='slot_predict')\n","            per_example_loss = -log_likelihood\n","            loss = tf.reduce_sum(-log_likelihood)\n","            \n","        return (loss, per_example_loss, logits, predict)\n","\n","         \n","        \n","def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n","                     num_train_steps, num_warmup_steps, use_tpu,\n","                     use_one_hot_embeddings):\n","    def model_fn(features, labels, mode, params):\n","        tf.logging.info(\"*** Features ***\")\n","        for name in sorted(features.keys()):\n","            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n","        input_ids = features[\"input_ids\"]\n","        input_mask = features[\"input_mask\"]\n","        segment_ids = features[\"segment_ids\"]\n","        label_ids = features[\"label_ids\"]\n","        #label_mask = features[\"label_mask\"]\n","        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","\n","        (total_loss,  per_example_loss,logits,predicts) = create_model(\n","            bert_config, is_training, input_ids, input_mask,segment_ids, label_ids,\n","            num_labels, use_one_hot_embeddings)\n","        tvars = tf.trainable_variables()\n","        scaffold_fn = None\n","        if init_checkpoint:\n","            (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars,init_checkpoint)\n","            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","            if use_tpu:\n","                def tpu_scaffold():\n","                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","                    return tf.train.Scaffold()\n","                scaffold_fn = tpu_scaffold\n","            else:\n","                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","        tf.logging.info(\"**** Trainable Variables ****\")\n","\n","        for var in tvars:\n","            init_string = \"\"\n","            if var.name in initialized_variable_names:\n","                init_string = \", *INIT_FROM_CKPT*\"\n","            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n","                            init_string)\n","        output_spec = None\n","        if mode == tf.estimator.ModeKeys.TRAIN:\n","            train_op = optimization.create_optimizer(\n","                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n","            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","                mode=mode,\n","                loss=total_loss,\n","                train_op=train_op,\n","                scaffold_fn=scaffold_fn)\n","        elif mode == tf.estimator.ModeKeys.EVAL:\n","            \n","            def metric_fn(per_example_loss, label_ids, logits):\n","            # def metric_fn(label_ids, logits):\n","                predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n","                precision = tf_metrics.precision(label_ids,predictions,num_labels,[i for i in range(1,num_labels-2)],average=\"macro\")\n","                recall = tf_metrics.recall(label_ids,predictions,num_labels,[i for i in range(1,num_labels-2)],average=\"macro\")\n","                f = tf_metrics.f1(label_ids,predictions,num_labels,[i for i in range(1,num_labels-2)],average=\"macro\")\n","                #\n","                return {\n","                    \"eval_precision\":precision,\n","                    \"eval_recall\":recall,\n","                    \"eval_f\": f,\n","                    #\"eval_loss\": loss,\n","                }\n","            eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n","            # eval_metrics = (metric_fn, [label_ids, logits])\n","            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","                mode=mode,\n","                loss=total_loss,\n","                eval_metrics=eval_metrics,\n","                scaffold_fn=scaffold_fn)\n","        else:\n","            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","                mode = mode,predictions= predicts,scaffold_fn=scaffold_fn\n","            )\n","        return output_spec\n","    return model_fn\n","\n","\n","def main():\n","    tf.logging.set_verbosity(tf.logging.INFO)\n","    processors = {\n","        \"ner\": NerProcessor,\n","        \"kashgari\": kashgariProcessor\n","    }\n","    if not do_train and not do_eval and not do_predict:\n","        raise ValueError(\"At least one of `do_train` or `do_eval` or `do_predict` must be True.\")\n","\n","    bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n","\n","    if max_seq_length > bert_config.max_position_embeddings:\n","        raise ValueError(\n","            \"Cannot use sequence length %d because the BERT model \"\n","            \"was only trained up to sequence length %d\" %\n","            (max_seq_length, bert_config.max_position_embeddings))\n","    global task_name,output_dir\n","    task_name = task_name.lower()\n","    if task_name not in processors:\n","        raise ValueError(\"Task not found: %s\" % (task_name))\n","    processor = processors[task_name]()\n","    global num_labels\n","    label_list = processor.get_labels()\n","    num_labels = len(label_list)+1\n","    tokenizer = tokenization.FullTokenizer(\n","        vocab_file=vocab_file, do_lower_case=do_lower_case)\n","    tpu_cluster_resolver = None\n","    if use_tpu and False:\n","        tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n","            tpu_name, zone=tpu_zone, project=gcp_project)\n","\n","    is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n","\n","    run_config = tf.contrib.tpu.RunConfig(\n","        cluster=tpu_cluster_resolver,\n","        master=master,\n","        model_dir=output_dir,\n","        save_checkpoints_steps=save_checkpoints_steps,\n","        tpu_config=tf.contrib.tpu.TPUConfig(\n","            iterations_per_loop=iterations_per_loop,\n","            num_shards=num_tpu_cores,\n","            per_host_input_for_training=is_per_host))\n","\n","    train_examples = None\n","    num_train_steps = None\n","    num_warmup_steps = None\n","    global traindata_dir\n","    if do_train:\n","        \n","        train_examples = processor.get_train_examples(traindata_dir)\n","        num_train_steps = int(\n","            len(train_examples) / train_batch_size * num_train_epochs)\n","        num_warmup_steps = int(num_train_steps * warmup_proportion)\n","    \n","    model_fn = model_fn_builder(\n","        bert_config=bert_config,\n","        num_labels=num_labels+1,\n","        init_checkpoint=init_checkpoint,\n","        learning_rate=learning_rate,\n","        num_train_steps=num_train_steps,\n","        num_warmup_steps=num_warmup_steps,\n","        use_tpu=use_tpu,\n","        use_one_hot_embeddings=use_tpu)\n","\n","    estimator = tf.contrib.tpu.TPUEstimator(\n","        use_tpu=use_tpu,\n","        model_fn=model_fn,\n","        config=run_config,\n","        train_batch_size=train_batch_size,\n","        eval_batch_size=eval_batch_size,\n","        predict_batch_size=predict_batch_size)\n","\n","    if do_train:\n","        train_file = os.path.join(output_dir, \"train.tf_record\")\n","        filed_based_convert_examples_to_features(\n","            train_examples, label_list, max_seq_length, tokenizer, train_file)\n","        tf.logging.info(\"***** Running training *****\")\n","        tf.logging.info(\"  Num examples = %d\", len(train_examples))\n","        tf.logging.info(\"  Batch size = %d\", train_batch_size)\n","        tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","        train_input_fn = file_based_input_fn_builder(\n","            input_file=train_file,\n","            seq_length=max_seq_length,\n","            is_training=True,\n","            drop_remainder=True)\n","        estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","    if do_eval:\n","        eval_examples = processor.get_dev_examples(traindata_dir)\n","        eval_file = os.path.join(output_dir, \"eval.tf_record\")\n","        filed_based_convert_examples_to_features(\n","            eval_examples, label_list, max_seq_length, tokenizer, eval_file)\n","\n","        tf.logging.info(\"***** Running evaluation *****\")\n","        tf.logging.info(\"  Num examples = %d\", len(eval_examples))\n","        tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n","        eval_steps = None\n","        if use_tpu:\n","            eval_steps = int(len(eval_examples) / eval_batch_size)\n","        eval_drop_remainder = True if use_tpu else False\n","        eval_input_fn = file_based_input_fn_builder(\n","            input_file=eval_file,\n","            seq_length=max_seq_length,\n","            is_training=False,\n","            drop_remainder=eval_drop_remainder)\n","        result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n","        output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n","        with open(output_eval_file, \"w\") as writer:\n","            tf.logging.info(\"***** Eval results *****\")\n","            for key in sorted(result.keys()):\n","                tf.logging.info(\"  %s = %s\", key, str(result[key]))\n","                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","    if do_predict:\n","        token_path = os.path.join(output_dir, \"token_test.txt\")\n","        with open('./output/label2id.pkl','rb') as rf:\n","            label2id = pickle.load(rf)\n","            id2label = {value:key for key,value in label2id.items()}\n","        if os.path.exists(token_path):\n","            os.remove(token_path)\n","        predict_examples = processor.get_test_examples(traindata_dir)\n","\n","        predict_file = os.path.join(output_dir, \"predict.tf_record\")\n","        filed_based_convert_examples_to_features(predict_examples, label_list,\n","                                                max_seq_length, tokenizer,\n","                                                predict_file,mode=\"test\")\n","                            \n","        tf.logging.info(\"***** Running prediction*****\")\n","        tf.logging.info(\"  Num examples = %d\", len(predict_examples))\n","        tf.logging.info(\"  Batch size = %d\", predict_batch_size)\n","        if use_tpu:\n","            # Warning: According to tpu_estimator.py Prediction on TPU is an\n","            # experimental feature and hence not supported here\n","            raise ValueError(\"Prediction in TPU not supported\")\n","        predict_drop_remainder = True if use_tpu else False\n","        predict_input_fn = file_based_input_fn_builder(\n","            input_file=predict_file,\n","            seq_length=max_seq_length,\n","            is_training=False,\n","            drop_remainder=predict_drop_remainder)\n","        \n","\n","\n","        \n","\n","        \n","        \n","\n","\n","        result = estimator.predict(input_fn=predict_input_fn)\n","        output_predict_file = os.path.join(output_dir, \"label_test.csv\")\n","\n","\n","\n","\n","\n","\n","\n","        with open(output_predict_file,'w') as writer:\n","            result_array=[]\n","            for prediction in result:\n","                for index,id in enumerate(prediction):\n","                    if id!=0:\n","                        result_array.append(id2label[id])\n","            writer.write(\"\\n\".join(result_array))\n","    print(\"result_array: \", result_array)\n","    sample_array_text,sample_array_ans = [],[]\n","    for example in predict_examples:\n","      \n","      temp_text = example.text\n","      temp_label = example.label\n","      sample_array_text.append(\"[CLS]\")\n","      sample_array_ans.append(\"[CLS]\")\n","      sample_array_text.extend(temp_text.split(\" \")[:max_seq_length-2])\n","      sample_array_ans.extend(temp_label.split(\" \")[:max_seq_length-2])\n","      sample_array_text.append(\"[SEP]\")\n","      sample_array_ans.append(\"[SEP]\")\n","\n"," \n","\n","    # output\n","    with open(os.path.join(output_dir, \"test_samples_results.csv\"), 'w') as writer:\n","        output_array = [\" \"+\"\\t\"+\"預測\" + '\\t' + \"正解\"+ '\\t' + \"內容\"]\n","        for p, s, a in zip(result_array,sample_array_text,sample_array_ans):\n","            token = \"o\" if a == p else \"x\"\n","            output_array.append(token+ '\\t'+p + '\\t' + a+ '\\t' + s)\n","\n","        writer.write(\"\\n\".join(output_array))\n","    \n","if __name__ == \"__main__\":\n","    \n","    main()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"rSnYxfwVR1qz","colab_type":"text"},"source":["# on GitHub"]},{"cell_type":"code","metadata":{"id":"SoUqn6BlR50R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0f030ba4-b559-4ad5-c62c-7652a104ff1b","executionInfo":{"status":"ok","timestamp":1574379079504,"user_tz":-480,"elapsed":86060,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}}},"source":["#! usr/bin/env python3\n","# -*- coding:utf-8 -*-\n","\"\"\"\n","Copyright 2018 The Google AI Language Team Authors.\n","BASED ON Google_BERT.\n","@Author:zhoukaiyin\n","Adjust code for chinese ner\n","\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import collections\n","import os\n","import modeling\n","import optimization\n","import tokenization\n","import tensorflow as tf\n","from sklearn.metrics import f1_score,precision_score,recall_score\n","from tensorflow.python.ops import math_ops\n","import tf_metrics\n","import pickle\n","import json\n","import os\n","from kashgari.corpus import ChineseDailyNerCorpus\n","\n","\n","\n","\n","\n","traindata_dir = 'data/'\n","bert_config_file = 'base_model/chinese-wwm_L-12_H-768_A-12/bert_config.json'\n","task_name = \"kashgari\"\n","output_dir = './output/'\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","init_checkpoint = 'base_model/chinese-wwm_L-12_H-768_A-12/bert_model.ckpt'\n","do_lower_case = True\n","max_seq_length =128\n","use_tpu = False\n","do_train = True\n","do_eval = True\n","do_predict = True\n","train_batch_size = 16\n","eval_batch_size = 16\n","predict_batch_size = 16\n","learning_rate = 5e-5\n","num_train_epochs = 5\n","warmup_proportion = 0.1\n","save_checkpoints_steps = 1000\n","iterations_per_loop = 1000\n","vocab_file = './base_model/chinese-wwm_L-12_H-768_A-12/vocab.txt'\n","master = None\n","num_tpu_cores = 8\n","crf_loss_method=True\n","\n","\n","\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text, label=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","          guid: Unique id for the example.\n","          text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","          label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text = text\n","        self.label = label\n","\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_ids,):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_ids = label_ids\n","        #self.label_mask = label_mask\n","\n","\n","class DataProcessor(object):\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()\n","\n","    @classmethod\n","    def _read_data(cls, input_file):\n","        \"\"\"Reads a BIO data.\"\"\"\n","        with open(input_file) as f:\n","            lines = []\n","            words = []\n","            labels = []\n","            for line in f:\n","                contends = line.strip()\n","                word = line.strip().split(' ')[0]\n","                label = line.strip().split(' ')[-1]\n","                if contends.startswith(\"-DOCSTART-\"):\n","                    words.append('')\n","                    continue\n","                # if len(contends) == 0 and words[-1] == '。':\n","                if len(contends) == 0:\n","                    l = ' '.join([label for label in labels if len(label) > 0])\n","                    w = ' '.join([word for word in words if len(word) > 0])\n","                    lines.append([l, w])\n","                    words = []\n","                    labels = []\n","                    continue\n","                words.append(word)\n","                labels.append(label)\n","            return lines\n","\n","class NerProcessor_from_file(DataProcessor):\n","    def get_train_examples(self, data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_train.txt\")), \"train\"\n","        )\n","\n","    def get_dev_examples(self, data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_dev_and_test.txt\")), \"dev\"\n","        )\n","\n","    def get_test_examples(self,data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_dev_and_test.txt\")), \"test\")\n","\n","\n","    def get_labels(self):\n","        # prevent potential bug for chinese text mixed with english text\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\",\"[SEP]\"]\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"X\",\"[CLS]\",\"[SEP]\"]\n","        global traindata_dir\n","        examples = self.get_train_examples(traindata_dir)\n","        tags = [\"[CLS]\",\"[SEP]\"]\n","        for e in examples:\n","            \n","            for l in e.label.split(\" \"):\n","                if l not in tags:\n","                  tags.append(l)\n","        return tags\n","        #return [\"o\", \"B-CHA\", \"I-CHA\", \"B-TIM\", \"I-TIM\", \"B-MON\", \"I-MON\", \"B-PER\", \"I-PER\",\"[CLS]\",\"[SEP]\"]\n","\n","    def _create_example(self, lines, set_type):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text = tokenization.convert_to_unicode(line[1])\n","            label = tokenization.convert_to_unicode(line[0])\n","            examples.append(InputExample(guid=guid, text=text, label=label))\n","        return examples\n","class kashgariProcessor(DataProcessor):\n","    \"\"\"\n","    from kashgari.corpus import ChineseDailyNerCorpus\n","    train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","    valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","    test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","    \"\"\"\n","    \n","    def get_train_examples(self,*args):\n","        train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","         \n","        return self._create_example(self.load_data2set(train_x, train_y), \"train\")\n","\n","    def get_dev_examples(self,*args):\n","        valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","        return self._create_example(self.load_data2set(valid_x, valid_y), \"dev\")\n","\n","    def get_test_examples(self,*args):\n","        test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","        return self._create_example(self.load_data2set(test_x, test_y,max_num=1000), \"test\")\n","\n","\n","    def load_data2set(self,set_x, set_y, max_num = 50000):\n","      \n","      data_set = []\n","      idx = 0\n","      sent_text,sent_slot=\"\",\"\"\n","      for label,ans in zip(set_x,set_y):\n","          idx+=1\n","          if idx > max_num and max_num !=-1:\n","            break\n","          sent_text = \" \".join(label)\n","          sent_slot = \" \".join(ans)\n","          data_set.append([sent_text,sent_slot])\n","          \n","          \n","          \n","      print(\"data_set: \",data_set[:50])\n","      return data_set\n","    def get_labels(self):\n","        # prevent potential bug for chinese text mixed with english text\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\",\"[SEP]\"]\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"X\",\"[CLS]\",\"[SEP]\"]\n","        examples = self.get_train_examples()\n","        tags = [\"[CLS]\",\"[SEP]\"]\n","        \n","        for idx,e in enumerate(examples):\n","            temp_tags = e.label.split(\" \")\n","            for n_tag in temp_tags:\n","              if n_tag not in tags:\n","                tags.append(n_tag)\n","        return tags\n","\n","    def _create_example(self, lines, set_type):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text = tokenization.convert_to_unicode(line[0])\n","            label = tokenization.convert_to_unicode(line[1])\n","            examples.append(InputExample(guid=guid, text=text, label=label))\n","        return examples\n","def write_tokens(tokens,mode):\n","    if mode==\"test\":\n","        path = os.path.join(output_dir, \"token_\"+mode+\".txt\")\n","        wf = open(path,'a')\n","        for token in tokens:\n","            if token!=\"**NULL**\":\n","                wf.write(token+'\\n')\n","        wf.close()\n","\n","def convert_single_example(ex_index, example, label_map, max_seq_length, tokenizer,mode):\n","    textlist = example.text.split(' ')\n","    labellist = example.label.split(' ')\n","    tokens = []\n","    labels = []\n","    # print(textlist)\n","    for i, word in enumerate(textlist):\n","        token = tokenizer.tokenize(word)\n","        # print(token)\n","        tokens.extend(token)\n","        label_1 = labellist[i]\n","        # print(label_1)\n","        for m in range(len(token)):\n","            if m == 0:\n","                labels.append(label_1)\n","            else:\n","                labels.append(\"X\")\n","        # print(tokens, labels)\n","    # tokens = tokenizer.tokenize(example.text)\n","    if len(tokens) >= max_seq_length - 1:\n","        tokens = tokens[0:(max_seq_length - 2)]\n","        labels = labels[0:(max_seq_length - 2)]\n","    ntokens = []\n","    segment_ids = []\n","    label_ids = []\n","    ntokens.append(\"[CLS]\")\n","    segment_ids.append(0)\n","    # append(\"O\") or append(\"[CLS]\") not sure!\n","    label_ids.append(label_map[\"[CLS]\"])\n","    for i, token in enumerate(tokens):\n","        ntokens.append(token)\n","        segment_ids.append(0)\n","        label_ids.append(label_map[labels[i]])\n","    ntokens.append(\"[SEP]\")\n","    segment_ids.append(0)\n","    # append(\"O\") or append(\"[SEP]\") not sure!\n","    label_ids.append(label_map[\"[SEP]\"])\n","    input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n","    input_mask = [1] * len(input_ids)\n","    #label_mask = [1] * len(input_ids)\n","    while len(input_ids) < max_seq_length:\n","        input_ids.append(0)\n","        input_mask.append(0)\n","        segment_ids.append(0)\n","        # we don't concerned about it!\n","        label_ids.append(0)\n","        ntokens.append(\"**NULL**\")\n","        #label_mask.append(0)\n","    # print(len(input_ids))\n","    assert len(input_ids) == max_seq_length\n","    assert len(input_mask) == max_seq_length\n","    assert len(segment_ids) == max_seq_length\n","    assert len(label_ids) == max_seq_length\n","    #assert len(label_mask) == max_seq_length\n","\n","    if ex_index < 5:\n","        tf.logging.info(\"*** Example ***\")\n","        tf.logging.info(\"guid: %s\" % (example.guid))\n","        tf.logging.info(\"tokens: %s\" % \" \".join(\n","            [tokenization.printable_text(x) for x in tokens]))\n","        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n","        tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n","        tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n","        tf.logging.info(\"label_ids: %s\" % \" \".join([str(x) for x in label_ids]))\n","        #tf.logging.info(\"label_mask: %s\" % \" \".join([str(x) for x in label_mask]))\n","\n","    feature = InputFeatures(\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        segment_ids=segment_ids,\n","        label_ids=label_ids,\n","        #label_mask = label_mask\n","    )\n","    write_tokens(ntokens,mode)\n","    return feature\n","\n","\n","def filed_based_convert_examples_to_features(\n","        examples, label_list, max_seq_length, tokenizer, output_file,mode=None\n","):\n","    label_map = {}\n","    for (i, label) in enumerate(label_list,1):\n","        label_map[label] = i\n","    ###\n","    with open('./output/label2id.pkl','wb') as w:\n","        pickle.dump(label_map,w)\n","\n","    writer = tf.python_io.TFRecordWriter(output_file)\n","    for (ex_index, example) in enumerate(examples):\n","        if ex_index % 5000 == 0:\n","            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n","        feature = convert_single_example(ex_index, example, label_map, max_seq_length, tokenizer,mode)\n","        \n","        def create_int_feature(values):\n","            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n","            return f\n","\n","        features = collections.OrderedDict()\n","        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n","        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n","        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n","        features[\"label_ids\"] = create_int_feature(feature.label_ids)\n","        #features[\"label_mask\"] = create_int_feature(feature.label_mask)\n","        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n","        writer.write(tf_example.SerializeToString())\n","\n","\n","def file_based_input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n","\n","    name_to_features = {\n","        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n","        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","        \"label_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","        # \"label_ids\":tf.VarLenFeature(tf.int64),\n","        #\"label_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n","    }\n","\n","    def _decode_record(record, name_to_features):\n","        example = tf.parse_single_example(record, name_to_features)\n","        for name in list(example.keys()):\n","            t = example[name]\n","            if t.dtype == tf.int64:\n","                t = tf.to_int32(t)\n","            example[name] = t\n","        return example\n","\n","    def input_fn(params):\n","        batch_size = params[\"batch_size\"]\n","        d = tf.data.TFRecordDataset(input_file)\n","        if is_training:\n","            d = d.repeat()\n","            d = d.shuffle(buffer_size=100)\n","        d = d.apply(tf.contrib.data.map_and_batch(\n","            lambda record: _decode_record(record, name_to_features),\n","            batch_size=batch_size,\n","            drop_remainder=drop_remainder\n","        ))\n","        return d\n","\n","    return input_fn\n","\n","\n","def create_model(bert_config, is_training, input_ids, input_mask,\n","                 segment_ids, labels, num_labels, use_one_hot_embeddings):\n","    model = modeling.BertModel(\n","        config=bert_config,\n","        is_training=is_training,\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        token_type_ids=segment_ids,\n","        use_one_hot_embeddings=use_one_hot_embeddings\n","    )\n","\n","    output_layer = model.get_sequence_output()\n","\n","    hidden_size = output_layer.shape[-1].value\n","\n","    output_weight = tf.get_variable(\n","        \"output_weights\", [num_labels, hidden_size],\n","        initializer=tf.truncated_normal_initializer(stddev=0.02)\n","    )\n","    output_bias = tf.get_variable(\n","        \"output_bias\", [num_labels], initializer=tf.zeros_initializer()\n","    )\n","    with tf.variable_scope(\"loss\"):\n","        global crf_loss_method\n","        if crf_loss_method is False:\n","            if is_training:\n","                output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","            output_layer = tf.reshape(output_layer, [-1, hidden_size])\n","            logits = tf.matmul(output_layer, output_weight, transpose_b=True)\n","            logits = tf.nn.bias_add(logits, output_bias)\n","            logits = tf.reshape(logits, [-1, max_seq_length, num_labels])\n","            # mask = tf.cast(input_mask,tf.float32)\n","            # loss = tf.contrib.seq2seq.sequence_loss(logits,labels,mask)\n","            # return (loss, logits, predict)\n","            ##########################################################################\n","            log_probs = tf.nn.log_softmax(logits, axis=-1)\n","            one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","            per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","            loss = tf.reduce_sum(per_example_loss)\n","            probabilities = tf.nn.softmax(logits, axis=-1)\n","            predict = tf.argmax(probabilities,axis=-1)\n","            \n","            ##########################################################################\n","        else:\n","            logits = tf.layers.dense(\n","                inputs=output_layer,\n","                units=num_labels,\n","                use_bias=True,\n","                bias_initializer=tf.zeros_initializer(),\n","                # kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n","                kernel_initializer=tf.contrib.layers.xavier_initializer()\n","            )\n","            mask_length = tf.reduce_sum(input_mask, axis=1)\n","\n","            log_likelihood, transition = tf.contrib.crf.crf_log_likelihood(\n","                inputs=logits,\n","                tag_indices=labels,\n","                sequence_lengths=mask_length)\n","\n","            decode_tags, best_score =  tf.contrib.crf.crf_decode(\n","                potentials=logits,\n","                transition_params=transition,\n","                sequence_length=mask_length)\n","\n","            predict = tf.identity(decode_tags, name='slot_predict')\n","            per_example_loss = -log_likelihood\n","            loss = tf.reduce_sum(-log_likelihood)\n","            \n","        return (loss, per_example_loss, logits, predict)\n","\n","         \n","        \n","def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n","                     num_train_steps, num_warmup_steps, use_tpu,\n","                     use_one_hot_embeddings):\n","    def model_fn(features, labels, mode, params):\n","        tf.logging.info(\"*** Features ***\")\n","        for name in sorted(features.keys()):\n","            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n","        input_ids = features[\"input_ids\"]\n","        input_mask = features[\"input_mask\"]\n","        segment_ids = features[\"segment_ids\"]\n","        label_ids = features[\"label_ids\"]\n","        #label_mask = features[\"label_mask\"]\n","        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","\n","        (total_loss,  per_example_loss,logits,predicts) = create_model(\n","            bert_config, is_training, input_ids, input_mask,segment_ids, label_ids,\n","            num_labels, use_one_hot_embeddings)\n","        tvars = tf.trainable_variables()\n","        scaffold_fn = None\n","        if init_checkpoint:\n","            (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars,init_checkpoint)\n","            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","            if use_tpu:\n","                def tpu_scaffold():\n","                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","                    return tf.train.Scaffold()\n","                scaffold_fn = tpu_scaffold\n","            else:\n","                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","        tf.logging.info(\"**** Trainable Variables ****\")\n","\n","        for var in tvars:\n","            init_string = \"\"\n","            if var.name in initialized_variable_names:\n","                init_string = \", *INIT_FROM_CKPT*\"\n","            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n","                            init_string)\n","        output_spec = None\n","        if mode == tf.estimator.ModeKeys.TRAIN:\n","            train_op = optimization.create_optimizer(\n","                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n","            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","                mode=mode,\n","                loss=total_loss,\n","                train_op=train_op,\n","                scaffold_fn=scaffold_fn)\n","        elif mode == tf.estimator.ModeKeys.EVAL:\n","            \n","            def metric_fn(per_example_loss, label_ids, logits):\n","            # def metric_fn(label_ids, logits):\n","                predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n","                precision = tf_metrics.precision(label_ids,predictions,num_labels,[i for i in range(1,num_labels-2)],average=\"macro\")\n","                recall = tf_metrics.recall(label_ids,predictions,num_labels,[i for i in range(1,num_labels-2)],average=\"macro\")\n","                f = tf_metrics.f1(label_ids,predictions,num_labels,[i for i in range(1,num_labels-2)],average=\"macro\")\n","                #\n","                return {\n","                    \"eval_precision\":precision,\n","                    \"eval_recall\":recall,\n","                    \"eval_f\": f,\n","                    #\"eval_loss\": loss,\n","                }\n","            eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n","            # eval_metrics = (metric_fn, [label_ids, logits])\n","            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","                mode=mode,\n","                loss=total_loss,\n","                eval_metrics=eval_metrics,\n","                scaffold_fn=scaffold_fn)\n","        else:\n","            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","                mode = mode,predictions= predicts,scaffold_fn=scaffold_fn\n","            )\n","        return output_spec\n","    return model_fn\n","\n","\n","def main():\n","    tf.logging.set_verbosity(tf.logging.INFO)\n","    processors = {\n","        \"ner\": NerProcessor_from_file,\n","        \"kashgari\": kashgariProcessor\n","    }\n","    if not do_train and not do_eval and not do_predict:\n","        raise ValueError(\"At least one of `do_train` or `do_eval` or `do_predict` must be True.\")\n","\n","    bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n","\n","    if max_seq_length > bert_config.max_position_embeddings:\n","        raise ValueError(\n","            \"Cannot use sequence length %d because the BERT model \"\n","            \"was only trained up to sequence length %d\" %\n","            (max_seq_length, bert_config.max_position_embeddings))\n","    global task_name,output_dir\n","    task_name = task_name.lower()\n","    if task_name not in processors:\n","        raise ValueError(\"Task not found: %s\" % (task_name))\n","    processor = processors[task_name]()\n","    global num_labels\n","    label_list = processor.get_labels()\n","    num_labels = len(label_list)+1\n","    tokenizer = tokenization.FullTokenizer(\n","        vocab_file=vocab_file, do_lower_case=do_lower_case)\n","    tpu_cluster_resolver = None\n","    if use_tpu and False:\n","        tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n","            tpu_name, zone=tpu_zone, project=gcp_project)\n","\n","    is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n","\n","    run_config = tf.contrib.tpu.RunConfig(\n","        cluster=tpu_cluster_resolver,\n","        master=master,\n","        model_dir=output_dir,\n","        save_checkpoints_steps=save_checkpoints_steps,\n","        tpu_config=tf.contrib.tpu.TPUConfig(\n","            iterations_per_loop=iterations_per_loop,\n","            num_shards=num_tpu_cores,\n","            per_host_input_for_training=is_per_host))\n","\n","    train_examples = None\n","    num_train_steps = None\n","    num_warmup_steps = None\n","    global traindata_dir\n","    if do_train:\n","        \n","        train_examples = processor.get_train_examples(traindata_dir)\n","        num_train_steps = int(\n","            len(train_examples) / train_batch_size * num_train_epochs)\n","        num_warmup_steps = int(num_train_steps * warmup_proportion)\n","    \n","    model_fn = model_fn_builder(\n","        bert_config=bert_config,\n","        num_labels=num_labels+1,\n","        init_checkpoint=init_checkpoint,\n","        learning_rate=learning_rate,\n","        num_train_steps=num_train_steps,\n","        num_warmup_steps=num_warmup_steps,\n","        use_tpu=use_tpu,\n","        use_one_hot_embeddings=use_tpu)\n","\n","    estimator = tf.contrib.tpu.TPUEstimator(\n","        use_tpu=use_tpu,\n","        model_fn=model_fn,\n","        config=run_config,\n","        train_batch_size=train_batch_size,\n","        eval_batch_size=eval_batch_size,\n","        predict_batch_size=predict_batch_size)\n","\n","    if do_train:\n","        train_file = os.path.join(output_dir, \"train.tf_record\")\n","        filed_based_convert_examples_to_features(\n","            train_examples, label_list, max_seq_length, tokenizer, train_file)\n","        tf.logging.info(\"***** Running training *****\")\n","        tf.logging.info(\"  Num examples = %d\", len(train_examples))\n","        tf.logging.info(\"  Batch size = %d\", train_batch_size)\n","        tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","        train_input_fn = file_based_input_fn_builder(\n","            input_file=train_file,\n","            seq_length=max_seq_length,\n","            is_training=True,\n","            drop_remainder=True)\n","        estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","    if do_eval:\n","        eval_examples = processor.get_dev_examples(traindata_dir)\n","        eval_file = os.path.join(output_dir, \"eval.tf_record\")\n","        filed_based_convert_examples_to_features(\n","            eval_examples, label_list, max_seq_length, tokenizer, eval_file)\n","\n","        tf.logging.info(\"***** Running evaluation *****\")\n","        tf.logging.info(\"  Num examples = %d\", len(eval_examples))\n","        tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n","        eval_steps = None\n","        if use_tpu:\n","            eval_steps = int(len(eval_examples) / eval_batch_size)\n","        eval_drop_remainder = True if use_tpu else False\n","        eval_input_fn = file_based_input_fn_builder(\n","            input_file=eval_file,\n","            seq_length=max_seq_length,\n","            is_training=False,\n","            drop_remainder=eval_drop_remainder)\n","        result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n","        output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n","        with open(output_eval_file, \"w\") as writer:\n","            tf.logging.info(\"***** Eval results *****\")\n","            for key in sorted(result.keys()):\n","                tf.logging.info(\"  %s = %s\", key, str(result[key]))\n","                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","    if do_predict:\n","        token_path = os.path.join(output_dir, \"token_test.txt\")\n","        with open('./output/label2id.pkl','rb') as rf:\n","            label2id = pickle.load(rf)\n","            id2label = {value:key for key,value in label2id.items()}\n","        if os.path.exists(token_path):\n","            os.remove(token_path)\n","        predict_examples = processor.get_test_examples(traindata_dir)\n","\n","        predict_file = os.path.join(output_dir, \"predict.tf_record\")\n","        filed_based_convert_examples_to_features(predict_examples, label_list,\n","                                                max_seq_length, tokenizer,\n","                                                predict_file,mode=\"test\")\n","                            \n","        tf.logging.info(\"***** Running prediction*****\")\n","        tf.logging.info(\"  Num examples = %d\", len(predict_examples))\n","        tf.logging.info(\"  Batch size = %d\", predict_batch_size)\n","        if use_tpu:\n","            # Warning: According to tpu_estimator.py Prediction on TPU is an\n","            # experimental feature and hence not supported here\n","            raise ValueError(\"Prediction in TPU not supported\")\n","        predict_drop_remainder = True if use_tpu else False\n","        predict_input_fn = file_based_input_fn_builder(\n","            input_file=predict_file,\n","            seq_length=max_seq_length,\n","            is_training=False,\n","            drop_remainder=predict_drop_remainder)\n","        \n","        result = estimator.predict(input_fn=predict_input_fn)\n","        output_predict_file = os.path.join(output_dir, \"label_test.csv\")\n","\n","if __name__ == \"__main__\":\n","    \n","    main()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["data_set:  [['庞 大 的 奥 运 村 工 地 上 ， 一 边 是 1 5 0 0 名 工 人 在 紧 张 有 序 地 施 工 ， 一 边 是 未 来 奥 运 会 的 工 作 人 员 在 各 交 付 使 用 的 场 馆 、 道 路 、 车 站 等 上 岗 实 习 ， 场 馆 设 施 的 管 理 给 人 高 效 、 严 格 的 印 象 。', 'O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['新 型 消 毒 法 使 水 更 纯 净 本 报 讯 北 京 野 林 科 技 有 限 公 司 近 期 推 出 了 新 型 高 效 二 氧 化 氯 发 生 器 ， 这 种 发 生 器 通 过 电 解 盐 产 生 以 二 氧 化 氯 为 主 ， 伴 有 多 种 强 氧 化 气 体 的 混 合 气 体 ， 在 强 力 杀 菌 的 同 时 ， 不 产 生 氯 代 有 机 物 致 癌 物 质 ， 被 建 设 部 、 中 国 预 防 医 学 科 学 院 等 专 家 誉 为 新 一 代 安 全 型 水 消 毒 系 统 。', 'O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O'], ['她 说 ： “ 捐 一 所 ‘ 希 望 小 学 ’ 要 好 多 好 多 万 ， 我 得 打 多 少 年 工 才 能 挣 来 这 好 多 好 多 钱 呀 ？ ”', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['西 柏 坡 村 里 ， 无 私 、 勤 朴 、 坚 强 的 父 老 乡 亲 们 ， 大 多 告 别 了 土 房 老 屋 ， 搬 进 舒 心 适 意 的 新 居 。', 'B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['接 到 住 地 后 ， 照 例 是 盛 宴 接 风 洗 尘 ， 一 大 群 干 部 陪 宴 。', 'O O O O O O O O O O O O O O O O O O O O O O O O'], ['研 究 人 员 目 前 正 在 对 真 菌 的 安 全 性 进 行 试 验 ， 以 确 保 其 只 “ 攻 击 ” 罂 粟 ， 而 不 损 害 其 它 生 物 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['近 年 来 出 版 的 部 队 作 家 的 几 部 散 文 集 ， 它 们 以 新 的 艺 术 境 界 ， 使 人 们 在 这 些 方 面 获 得 了 某 种 满 足 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['如 今 婆 家 人 回 访 一 定 也 会 受 到 礼 尚 往 来 的 接 待 ， 获 得 圆 满 的 成 功 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['凡 具 有 大 专 以 上 学 历 ， 年 龄 在 2 0 岁 — 3 5 岁 之 间 ， 具 有 较 好 的 思 想 政 治 素 质 ， 能 够 适 应 农 村 基 础 教 育 和 文 化 、 科 技 、 卫 生 的 服 务 要 求 、 志 愿 为 贫 困 地 区 提 供 服 务 的 青 年 均 可 报 名 参 加 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['省 有 关 领 导 告 诉 记 者 ， 改 造 基 层 卫 生 院 有 专 项 资 金 ， 截 留 挪 用 职 工 工 资 是 违 法 的 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['两 个 星 期 前 ， 安 南 在 同 巴 总 理 谢 里 夫 的 一 次 电 话 交 谈 中 表 示 愿 意 在 巴 印 两 国 之 间 进 行 调 解 ， 并 决 定 先 派 特 使 来 南 亚 访 问 。', 'O O O O O O B-PER I-PER O O B-LOC O O B-PER I-PER I-PER O O O O O O O O O O O O O B-LOC B-LOC O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O'], ['今 年 ， 省 、 市 国 税 局 进 一 步 明 确 分 工 ， 对 重 点 欠 税 大 户 制 定 清 理 计 划 ， 跟 踪 检 查 ， 务 求 落 实 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['北 京 晴 1 3 ℃ ／ 2 7 ℃ 天 津 晴 1 5 ℃ ／ 2 6 ℃ 石 家 庄 晴 1 4 ℃ ／ 2 6 ℃ 太 原 多 云 转 晴 1 1 ℃ ／ 2 4 ℃ 呼 和 浩 特 晴 8 ℃ ／ 2 2 ℃ 沈 阳 晴 1 1 ℃ ／ 2 5 ℃ 大 连 晴 1 2 ℃ ／ 1 9 ℃ 长 春 多 云 转 晴 1 3 ℃ ／ 2 4 ℃ 哈 尔 滨 晴 1 0 ℃ ／ 2 5 ℃ 上 海 多 云 转 阴 1 5 ℃ ／ 2 3 ℃ 南 京 多 云 1 3 ℃ ／ 2 3 ℃ 杭 州 多 云 1 6 ℃ ／ 2 5 ℃ 合 肥 阴 转 小 雨 1 4 ℃ ／ 1 9 ℃ 福 州 小 雨 转 阴 2 2 ℃ ／ 2 9 ℃ 南 昌 多 云 转 阴 1 7 ℃ ／ 2 6 ℃ 济 南 多 云 转 晴 1 6 ℃ ／ 2 8 ℃ 青 岛 多 云 1 1 ℃ ／ 1 8 ℃ 郑 州 多 云 1 2 ℃ ／ 2 3 ℃ 武 汉 多 云 转 小 雨 1 5 ℃ ／ 1 8 ℃ 长 沙 多 云 1 5 ℃ ／ 2 5 ℃ 广 州 小 雨 2 4 ℃ ／ 3 0 ℃ 南 宁 小 雨 2 6 ℃ ／ 3 3 ℃ 海 口 多 云 转 雷 阵 雨 2 6 ℃ ／ 3 2 ℃ 成 都 小 雨 转 阴 1 7 ℃ ／ 2 3 ℃ 重 庆 小 雨 转 阴 1 8 ℃ ／ 2 6 ℃ 贵 阳 小 雨 转 阴 1 7 ℃ ／ 2 4 ℃ 昆 明 多 云 1 7 ℃ ／ 2 8 ℃ 拉 萨 多 云 1 0 ℃ ／ 2 0 ℃ 西 安 多 云 转 小 雨 1 5 ℃ ／ 2 0 ℃ 兰 州 多 云 1 3 ℃ ／ 2 4 ℃ 西 宁 多 云 9 ℃ ／ 2 0 ℃ 银 川 晴 转 多 云 1 1 ℃ ／ 2 2 ℃ 乌 鲁 木 齐 小 雨 转 中 雨 7 ℃ ／ 1 8 ℃ 台 北 小 雨 转 阴 2 3 ℃ ／ 3 1 ℃ 香 港 小 雨 2 4 ℃ ／ 2 9 ℃ 澳 门 小 雨 2 4 ℃ ／ 2 9 ℃ 东 京 小 雨 1 5 ℃ ／ 1 9 ℃ 曼 谷 多 云 2 8 ℃ ／ 3 6 ℃ 悉 尼 多 云 9 ℃ ／ 2 3 ℃ 卡 拉 奇 晴 2 5 ℃ ／ 3 9 ℃ 开 罗 多 云 1 8 ℃ ／ 2 7 ℃ 莫 斯 科 多 云 6 ℃ ／ 1 4 ℃ 法 兰 克 福 多 云 1 3 ℃ ／ 2 8 ℃ 巴 黎 多 云 1 4 ℃ ／ 2 9 ℃ 伦 敦 阴 1 2 ℃ ／ 2 4 ℃ 纽 约 多 云 1 1 ℃ ／ 1 6 ℃', 'B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O'], ['2 7 日 ， 第 一 届 国 际 禁 止 防 步 兵 地 雷 会 议 在 莫 斯 科 举 行 。', 'O O O O O O O O O O O O O O O O O O O B-LOC I-LOC I-LOC O O O'], ['第 2 8 分 钟 ， 巴 西 队 2 号 右 后 卫 卡 福 助 攻 至 苏 格 兰 队 禁 区 内 接 队 友 传 球 ， 他 在 起 脚 射 门 时 将 球 打 在 守 门 员 身 上 ， 皮 球 又 被 碰 至 苏 格 兰 队 回 防 的 3 号 后 卫 博 伊 德 身 上 ， 弹 入 网 内 。', 'O O O O O O B-ORG I-ORG I-ORG O O O O O B-PER I-PER O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O B-PER I-PER I-PER O O O O O O O O'], ['贵 州 茅 台 ， 一 向 有 “ 国 酒 ” 之 称 。', 'B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O'], ['记 者 认 识 的 一 位 女 士 就 属 于 “ 幸 运 鸟 ” ， 她 在 瑞 典 语 过 关 后 经 过 3 个 月 的 实 习 而 成 为 一 家 公 司 的 正 式 职 员 。', 'O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O'], ['中 国 社 会 科 学 院 美 国 研 究 所 所 长 王 缉 思', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER'], ['去 年 6 月 我 又 买 了 4 头 小 猪 ， 还 买 了 一 台 冰 柜 ， 办 了 一 个 小 卖 部 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 是 井 下 拼 命 三 郎 ， 用 这 双 手 挣 得 了 “ 采 煤 状 元 ” 。', 'O O O O O O O O O O O O O O O O O O O O O O O'], ['政 府 的 难 言 之 处 在 于 ， 受 去 年 1 1 月 国 会 通 过 的 “ 财 政 结 构 改 革 法 ” 的 制 约 ， 别 无 选 择 ， 否 则 就 是 政 府 违 法 。', 'O O O O O O O O O O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['山 东 曲 阜 发 生 一 起 恶 性 强 奸 杀 人 案 ， 司 法 机 关 查 获 了 小 贩 顾 新 华 。', 'B-LOC I-LOC B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O'], ['同 时 ， 妇 女 和 儿 童 问 题 也 是 国 际 社 会 关 注 的 重 大 社 会 问 题 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['本 报 北 京 6 月 2 2 日 讯 记 者 毕 全 忠 、 温 红 彦 报 道 ： 国 家 留 学 基 金 管 理 委 员 会 在 成 立 2 周 年 之 际 召 开 座 谈 会 ， 纪 念 邓 小 平 同 志 2 0 年 前 关 于 向 国 外 扩 大 派 遣 留 学 生 的 讲 话 。', 'O O B-LOC I-LOC O O O O O O O O B-PER I-PER I-PER O B-PER I-PER I-PER O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O'], ['它 取 决 于 交 易 中 介 机 构 的 数 量 和 质 量 。', 'O O O O O O O O O O O O O O O O O'], ['王 青 ： （ 《 中 国 家 庭 》 总 编 导 ） 我 们 把 节 目 的 主 题 思 想 定 位 在 ： “ 健 康 的 家 庭 和 家 庭 的 健 康 ” 上 。', 'B-PER I-PER O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['总 之 ， 求 同 求 异 是 一 种 积 极 的 态 度 和 方 针 ， 是 适 合 新 时 期 统 一 战 线 中 大 量 友 好 的 、 建 设 性 的 差 异 和 矛 盾 的 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['小 康 路 上 “ 领 头 雁 ” — — — 记 山 东 淄 博 市 上 庄 村 党 支 部 书 记 薛 安 郡', 'O O O O O O O O O O O O O B-LOC I-LOC B-LOC I-LOC I-LOC B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER'], ['对 小 企 业 安 置 下 岗 职 工 和 失 业 人 员 ， 根 据 条 件 给 予 安 置 补 助 费 和 社 会 保 险 补 助 费 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['因 此 ， 发 达 国 家 应 尽 快 采 取 措 施 ， 承 担 其 应 尽 的 责 任 ， 同 发 展 中 国 家 一 起 ， 共 同 保 护 环 境 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['到 了 9 0 年 代 后 ， 鉴 定 意 见 越 来 越 成 八 股 文 了 ， 能 拔 高 的 尽 量 拔 高 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['我 向 勇 士 们 跳 崖 的 方 向 鞠 躬 致 敬 后 ， 就 返 回 到 塔 下 。', 'O O O O O O O O O O O O O O O O O O O O O O O'], ['特 别 是 在 血 液 中 胆 固 醇 含 量 偏 高 时 ， 这 种 危 险 会 更 大 。', 'O O O O O O O O O O O O O O O O O O O O O O O O'], ['该 委 员 会 呼 吁 政 府 成 立 专 门 机 构 ， 以 对 学 术 欺 骗 行 为 展 开 有 效 的 独 立 调 查 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 说 ， 这 些 意 见 和 建 议 对 我 们 搞 好 教 育 整 顿 ， 改 进 和 加 强 工 作 有 很 大 启 发 和 帮 助 ， 对 各 位 委 员 提 出 的 意 见 、 建 议 和 批 评 ， 我 们 将 认 真 研 究 ， 逐 条 对 照 检 查 ， 推 动 教 育 整 顿 的 深 入 开 展 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['无 限 风 光 在 险 峰 ， 重 铸 辉 煌 的 日 子 还 在 前 面 ， 对 于 中 国 羽 毛 球 队 来 说 ， 既 能 顶 住 挫 折 的 考 验 ， 也 要 经 受 成 绩 和 赞 扬 声 的 考 验 ， 才 会 成 长 为 一 支 过 硬 的 优 秀 运 动 队 。', 'O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['中 原 油 田 从 改 革 入 手 ， 广 开 就 业 门 路 ， 坚 持 以 改 革 促 分 流 ， 以 发 展 促 安 置 ， 近 几 年 来 ， 先 后 分 流 安 置 富 余 职 工 近 3 万 人 ， 打 破 了 同 吃 油 田 一 锅 饭 的 局 面 。', 'B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['据 调 查 ， 死 者 之 夫 是 朝 鲜 王 朝 中 期 负 责 医 疗 行 政 和 教 育 事 务 的 典 医 监 官 员 李 命 正 。', 'O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O'], ['通 常 情 况 下 ， 被 称 作 p 5 3 的 基 因 在 绝 大 部 分 癌 症 患 者 身 上 会 产 生 变 异 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['日 本 不 仅 是 东 亚 经 济 模 式 的 设 计 者 ， 而 且 也 是 东 亚 经 济 模 式 的 投 资 者 。', 'B-LOC I-LOC O O O B-LOC I-LOC O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O'], ['他 说 ， 维 和 行 动 是 联 合 国 维 护 国 际 和 平 稳 定 的 重 要 手 段 。', 'O O O O O O O O B-ORG I-ORG I-ORG O O O O O O O O O O O O O O'], ['因 此 ， 朱 利 亚 斯 的 两 个 朋 友 先 后 退 出 ， 这 家 新 生 的 “ 三 资 企 业 ” 变 成 了 “ 独 家 经 营 ” 。', 'O O O B-PER I-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['前 年 1 月 在 香 港 ， 地 铁 、 电 车 加 计 程 车 ， 转 遍 了 香 港 城 区 的 街 市 。', 'O O O O O B-LOC I-LOC O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O'], ['毕 竟 ， 她 们 的 国 际 比 赛 经 验 太 少 ， 报 名 表 上 国 际 比 赛 场 次 一 栏 ， 中 国 队 的 大 部 分 球 员 没 有 超 过 1 0 场 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG O O O O O O O O O O O O O O'], ['清 明 上 河 新 画 卷 — — — 河 南 开 封 县 创 建 文 明 县 城 记 （ 附 图 片 1 张 ）', 'O O O O O O O O O O B-LOC I-LOC B-LOC I-LOC I-LOC O O O O O O O O O O O O O O'], ['但 从 今 年 5 月 底 以 来 ， 美 国 股 市 已 连 续 几 天 低 迷 。', 'O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O'], ['总 队 领 导 认 识 到 ， 要 提 高 官 兵 的 素 质 ， 带 出 过 硬 的 队 伍 ， 必 须 从 干 部 队 伍 自 身 的 “ 硬 化 ” 做 起 ， 依 据 部 队 干 部 工 作 三 个 条 例 ， 参 照 地 方 干 部 管 理 经 验 ， 制 定 出 了 一 套 干 部 考 核 、 考 试 、 奖 惩 、 升 降 和 专 业 技 能 达 标 等 量 化 标 准 ， 把 干 部 自 身 素 质 的 高 低 ， 与 其 职 级 升 降 、 待 遇 好 坏 挂 起 钩 来 ， 真 正 做 到 看 实 绩 用 干 部 、 按 标 准 比 优 劣 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['图 为 在 福 井 县 博 物 馆 展 出 的 恐 龙 化 石 。', 'O O O B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O'], ['在 最 近 中 关 村 电 脑 节 举 办 的 论 坛 上 ， 专 家 们 提 出 ： 网 络 电 话 将 挑 战 传 统 电 话 。', 'O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['副 省 长 黄 懋 衡 是 主 管 卫 生 的 ， 孙 用 和 是 主 管 绿 化 的 ， 他 们 埋 头 清 垃 圾 、 捡 纸 屑 ， 有 时 插 空 商 讨 如 何 加 强 配 合 ， 把 英 雄 城 建 设 得 更 美 更 卫 生 。', 'O O O B-PER I-PER I-PER O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O']]\n","data_set:  [['他 说 ， 学 邯 钢 、 抓 管 理 、 增 效 益 要 把 握 邯 钢 经 验 的 实 质 和 精 髓 ， 关 键 是 要 建 立 适 应 市 场 经 济 的 企 业 管 理 ， 使 管 理 适 应 企 业 走 向 市 场 的 现 实 要 求 。', 'O O O O B-ORG I-ORG O O O O O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['总 投 资 达 1 3 ． 2 6 亿 元 的 郑 州 中 原 制 药 厂 因 盲 目 引 进 不 成 熟 的 国 外 技 术 设 备 ， 自 1 9 9 2 年 试 车 后 一 直 不 能 正 常 生 产 。', 'O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['在 南 斯 拉 夫 政 府 看 来 ， 造 成 上 述 恶 果 的 罪 魁 是 阿 族 非 法 武 装 科 索 沃 解 放 军 。', 'O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O'], ['而 且 ， 马 列 主 义 作 为 一 种 科 学 真 理 ， 它 既 不 需 要 、 也 不 应 当 强 制 人 们 去 “ 宗 奉 ” 。', 'O O O B-PER B-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['不 如 此 ， 就 很 难 站 住 ， 更 不 要 说 站 在 世 界 和 时 代 的 前 列 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O'], ['○ 两 名 中 国 少 年 将 担 任 公 平 竞 争 大 使', 'O O O B-LOC I-LOC O O O O O O O O O O O'], ['因 为 它 出 口 知 识 产 权 产 品 的 量 太 大 ， 这 直 接 涉 及 国 家 利 益 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['从 这 个 意 义 上 说 ， 愿 意 『 回 家 问 问 孙 子 』 ， 是 值 得 赞 美 的 好 现 象 ， 比 起 老 是 慨 叹 『 人 心 不 古 』 『 一 代 不 如 一 代 』 ， 要 积 极 得 多 ， 有 价 值 得 多 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['“ 五 个 一 工 程 ” 的 入 选 作 品 ， 应 该 力 求 达 到 这 样 的 标 准 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O'], ['经 过 实 地 考 察 她 发 现 吴 窑 村 这 地 方 有 山 、 有 水 、 有 草 ， 正 适 合 搞 奶 羊 养 殖 ， 于 是 她 们 全 家 在 这 里 租 了 房 子 ， 过 上 现 代 “ 牧 羊 生 活 ” 。', 'O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['以 此 为 参 照 ， 国 内 已 有 的 一 些 常 规 赛 事 也 应 该 认 真 策 划 、 精 心 组 织 、 强 化 管 理 和 宣 传 ， 从 而 彻 底 改 变 旧 有 面 貌 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['佛 朗 科 在 店 里 挂 着 一 个 牌 子 ， 上 书 ： “ 这 里 要 做 该 做 的 事 ， 该 做 的 事 要 做 好 。 ”', 'B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['亲 人 以 香 甜 的 米 酒 与 香 喷 的 腊 肉 款 待 他 ， 可 是 这 位 忧 国 忧 民 的 三 闾 大 夫 岂 咽 得 下 这 份 真 情 呢 ？', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['由 于 这 个 问 题 涉 及 到 如 何 阐 述 中 国 近 代 史 的 基 本 线 索 ， 有 助 于 对 近 代 中 国 发 展 趋 向 的 认 识 与 把 握 ， 因 而 逐 步 成 为 学 者 们 普 遍 关 注 的 一 个 热 点 。', 'O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['三 是 始 终 坚 持 正 确 的 组 织 路 线 ， 努 力 建 设 高 素 质 的 党 政 领 导 干 部 队 伍 、 企 业 经 营 管 理 者 队 伍 和 科 技 人 才 队 伍 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 表 示 相 信 ， 克 林 顿 总 统 即 将 对 中 国 的 访 问 将 有 助 于 推 动 不 断 发 展 的 中 美 关 系 。', 'O O O O O O B-PER I-PER I-PER O O O O O B-LOC I-LOC O O O O O O O O O O O O O O B-LOC B-LOC O O O'], ['今 天 ， 胡 锦 涛 还 分 别 会 见 了 韩 中 友 协 会 长 朴 晟 容 、 韩 国 大 国 家 党 名 誉 总 裁 李 会 昌 等 政 界 和 经 济 界 人 士 ， 参 观 了 三 星 器 兴 半 导 体 工 厂 ， 看 望 了 驻 韩 使 馆 工 作 人 员 ， 驻 韩 中 资 机 构 代 表 、 留 学 生 和 旅 韩 华 侨 代 表 ， 并 鼓 励 他 们 为 发 展 中 韩 友 好 合 作 关 系 做 出 新 的 贡 献 。', 'O O O B-PER I-PER I-PER O O O O O O B-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O B-PER I-PER I-PER O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O B-ORG I-ORG I-ORG I-ORG O O O O O O B-LOC B-LOC O O O O O O O O O O O B-LOC B-LOC O O O O O O O O O O O O B-LOC B-LOC O O O O O O O O O O O O O'], ['临 汾 军 分 区 帮 助 军 属 脱 贫 致 富 本 报 讯 山 西 省 临 汾 军 分 区 动 员 全 区 人 武 系 统 广 泛 开 展 帮 扶 活 动 ， 去 年 重 点 帮 扶 的 八 百 零 一 户 贫 困 军 属 ， 经 年 底 军 地 双 方 联 合 验 收 ， 已 有 百 分 之 六 十 八 实 现 了 当 年 脱 贫 ； 七 个 县 市 的 贫 困 军 属 实 现 了 整 体 脱 贫 。', 'B-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC B-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['国 家 经 贸 委 主 任 盛 华 仁 等 参 加 了 会 见 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER O O O O O O O'], ['沈 阳 市 加 强 了 科 技 专 家 医 疗 保 健 、 健 康 疗 养 工 作 ， 并 积 极 筹 建 科 学 家 公 寓 ， 提 供 约 6 0 0 套 住 宅 ， 还 准 备 筹 集 蒋 新 松 基 金 ， 奖 励 贡 献 突 出 的 知 识 分 子 。', 'B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O'], ['那 是 1 9 9 5 年 ， 由 于 工 作 需 要 ， 我 走 上 了 芙 蓉 区 区 委 书 记 这 个 新 的 领 导 岗 位 ， 面 对 繁 忙 的 公 务 ， 无 休 止 的 会 议 和 应 酬 ， 读 书 学 习 这 块 精 神 的 园 地 几 乎 无 暇 耕 耘 。', 'O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['哥 伦 比 亚 警 方 日 前 宣 布 ， 奥 兰 迪 斯 是 本 月 6 日 在 大 西 洋 省 府 巴 兰 基 亚 市 被 捕 的 。', 'B-LOC I-LOC I-LOC I-LOC O O O O O O O B-PER I-PER I-PER I-PER O O O O O O B-LOC I-LOC I-LOC O O B-LOC I-LOC I-LOC I-LOC I-LOC O O O O'], ['济 宁 市 公 安 局 开 展 了 “ 民 警 进 万 家 ， 服 务 创 一 流 ” 的 爱 民 、 便 民 、 利 民 活 动 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['华 中 理 工 大 学 高 教 研 究 所 所 长 文 辅 相', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER'], ['董 建 华 表 示 ， 这 次 选 举 不 仅 充 分 表 现 了 港 人 爱 港 的 理 念 ， 更 充 分 表 现 出 市 民 对 落 实 『 一 国 两 制 』 、 『 港 人 治 港 』 充 满 信 心 。', 'B-PER I-PER I-PER O O O O O O O O O O O O O O B-LOC O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O B-LOC O O B-LOC O O O O O O'], ['从 总 体 看 ， 对 人 对 己 、 对 社 会 对 家 庭 ， 都 是 有 利 的 。', 'O O O O O O O O O O O O O O O O O O O O O O O'], ['我 们 创 建 的 一 流 大 学 就 是 要 担 负 起 弘 扬 中 华 民 族 优 秀 文 化 ， 吸 收 世 界 各 国 文 明 成 果 和 文 化 精 华 的 重 任 。', 'O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['中 国 财 政 部 长 项 怀 诚 在 会 议 发 言 中 全 面 介 绍 了 我 国 国 内 的 经 济 形 势 ， 以 及 为 使 国 民 经 济 持 续 、 快 速 、 健 康 地 发 展 所 采 取 的 一 系 列 措 施 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['首 次 双 方 都 没 有 进 球 ， 0 ∶ 0 的 比 分 令 3 ． 5 万 名 观 战 的 球 迷 大 失 所 望 ； 首 次 亮 出 红 牌 ， 保 加 利 亚 队 中 卫 南 科 夫 在 全 场 比 赛 结 束 前 几 分 钟 因 背 后 铲 人 严 重 犯 规 ， 被 罚 下 场 ； 在 中 国 职 业 足 球 联 赛 中 踢 球 的 队 员 （ 冈 波 斯 ） 首 次 出 现 在 世 界 杯 赛 场 上 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O'], ['深 圳 市 财 政 局 局 长 陈 锡 桃 表 示 ， 以 后 年 度 视 再 就 业 基 金 收 支 结 存 情 况 ， 按 实 际 需 要 纳 入 年 度 财 政 预 算 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['其 中 最 大 的 问 题 ， 我 认 为 现 在 培 养 出 的 人 才 知 识 面 窄 。', 'O O O O O O O O O O O O O O O O O O O O O O O O'], ['以 上 是 我 对 拍 摄 《 花 季 · 雨 季 》 的 一 点 追 求 ， 到 底 如 何 ， 有 待 观 众 评 定 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['因 此 可 以 认 为 ， 柬 大 选 的 准 备 工 作 将 继 续 朝 着 积 极 的 方 向 发 展 。', 'O O O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O'], ['与 此 同 时 ， 着 眼 于 未 来 ， 我 国 正 在 积 极 研 究 非 传 统 高 性 能 计 算 机 技 术 ， 以 适 应 2 1 世 纪 知 识 经 济 时 代 的 需 要 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['到 了 明 代 ， 铜 活 字 广 泛 应 用 ， 彩 色 印 刷 亦 告 问 世 。', 'O O O O O O O O O O O O O O O O O O O O O O'], ['美 国 航 空 航 天 局 的 科 学 家 6 日 公 布 了 美 国 火 星 环 球 观 测 者 号 飞 船 上 周 末 发 回 的 有 关 火 星 的 照 片 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O B-LOC I-LOC B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O B-LOC I-LOC O O O O'], ['常 听 有 的 教 师 说 ： “ 现 在 的 学 生 心 理 素 质 太 差 ， 不 来 点 厉 害 的 管 不 住 ， 管 得 太 厉 害 了 ， 又 怕 出 问 题 。 ”', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['李 玲 蔚 强 调 ， 年 轻 运 动 员 应 学 会 善 于 调 节 自 己 的 心 理 ， 提 高 自 身 对 大 赛 的 适 应 能 力 。', 'B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['柯 琦 充 分 调 动 自 己 长 于 行 草 书 法 的 潜 能 ， 发 挥 笔 法 和 墨 线 在 绘 形 造 境 中 的 主 导 作 用 及 激 情 的 抒 发 ， 以 速 多 于 缓 的 笔 法 ， 在 笔 与 笔 、 线 与 线 经 意 或 不 经 意 的 联 结 与 生 发 中 ， 表 现 总 体 势 态 ， 造 成 一 种 蕴 蓄 势 能 的 节 奏 韵 律 ， 使 画 中 形 成 似 静 而 实 动 的 独 特 的 表 现 风 格 。', 'B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['祖 祖 辈 辈 在 泥 土 里 刨 食 的 农 民 ， 办 起 了 各 种 各 样 的 工 厂 ， 创 造 了 奇 迹 般 的 辉 煌 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['韩 国 的 出 口 今 年 以 来 呈 下 降 趋 势 。', 'B-LOC I-LOC O O O O O O O O O O O O O'], ['凡 尔 赛 宫 ， 著 名 的 法 国 皇 家 园 林 ， 以 华 丽 的 宫 殿 和 广 阔 的 花 园 令 世 人 赞 叹 不 已 ； 迪 斯 尼 乐 园 ， 美 国 的 现 代 建 筑 ， 以 独 特 的 布 局 和 丰 富 的 内 涵 饮 誉 全 球 。', 'B-LOC I-LOC I-LOC I-LOC O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O'], ['但 历 史 ， 文 学 史 ， 就 是 这 样 残 酷 ， 十 年 之 后 ， 二 十 年 之 后 ， 留 下 的 只 有 凤 毛 麟 角 ， 余 皆 大 都 要 淹 到 尘 埃 里 去 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['有 碑 记 载 说 明 ， 这 宝 顶 山 造 像 始 建 于 南 宋 淳 熙 六 年 至 淳 佑 九 年 间 ， 历 时 七 十 余 载 ， 是 由 南 宋 僧 人 赵 智 凤 主 持 营 建 的 密 宗 道 场 。', 'O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O B-LOC I-LOC I-LOC I-LOC O'], ['从 社 会 （ 包 括 各 级 政 府 ） 方 面 来 看 ， 对 高 校 应 发 挥 的 功 能 与 作 用 也 认 识 不 足 ， 不 全 面 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['苏 格 兰 队 教 练 布 朗 说 ， 只 得 1 分 ， 很 失 望 ， 因 为 我 们 尽 了 一 切 努 力 想 赢 得 3 分 。', 'B-ORG I-ORG I-ORG I-ORG O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 个 道 理 也 是 极 浅 的 ， 一 看 就 能 明 白 。', 'O O O O O O O O O O O O O O O O O'], ['藏 在 花 蕊 里 的 姊 妹 节 ， 源 远 流 长 。', 'O O O O O O O O O O O O O O O'], ['他 说 ， 我 们 双 方 终 于 走 到 一 起 了 ， 这 是 一 种 进 步 。', 'O O O O O O O O O O O O O O O O O O O O O O'], ['在 一 次 意 外 事 故 中 双 腿 被 砸 断 、 造 成 终 生 残 废 的 宁 夏 彭 阳 县 山 区 农 民 李 志 远 ， 1 5 年 来 凭 着 一 腔 热 血 ， 拄 着 拐 杖 ， 挪 一 步 爬 两 步 ， 在 荒 山 秃 岭 上 种 植 桃 、 杏 、 杨 等 2 0 多 种 果 木 8 ． 6 万 株 ， 使 荒 山 变 得 郁 郁 葱 葱 ， 充 满 生 机 。', 'O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC B-LOC I-LOC I-LOC O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O']]\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fea770251e0>) includes params argument, but params are not passed to Estimator.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fea770251e0>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': './output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea6cf681d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': './output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea6cf681d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:_TPUContext: eval_on_tpu True\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:_TPUContext: eval_on_tpu True\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 20864\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 20864\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 他 说 ， 学 邯 钢 、 抓 管 理 、 增 效 益 要 把 握 邯 钢 经 验 的 实 质 和 精 髓 ， 关 键 是 要 建 立 适 应 市 场 经 济 的 企 业 管 理 ， 使 管 理 适 应 企 业 走 向 市 场 的 现 实 要 求 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 他 说 ， 学 邯 钢 、 抓 管 理 、 增 效 益 要 把 握 邯 钢 经 验 的 实 质 和 精 髓 ， 关 键 是 要 建 立 适 应 市 场 经 济 的 企 业 管 理 ， 使 管 理 适 应 企 业 走 向 市 场 的 现 实 要 求 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 800 6432 8024 2110 6935 7167 510 2831 5052 4415 510 1872 3126 4660 6206 2828 2995 6935 7167 5307 7741 4638 2141 6574 1469 5125 7767 8024 1068 7241 3221 6206 2456 4989 6844 2418 2356 1767 5307 3845 4638 821 689 5052 4415 8024 886 5052 4415 6844 2418 821 689 6624 1403 2356 1767 4638 4385 2141 6206 3724 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 800 6432 8024 2110 6935 7167 510 2831 5052 4415 510 1872 3126 4660 6206 2828 2995 6935 7167 5307 7741 4638 2141 6574 1469 5125 7767 8024 1068 7241 3221 6206 2456 4989 6844 2418 2356 1767 5307 3845 4638 821 689 5052 4415 8024 886 5052 4415 6844 2418 821 689 6624 1403 2356 1767 4638 4385 2141 6206 3724 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 6 7 3 3 3 3 3 3 3 3 3 3 3 6 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 6 7 3 3 3 3 3 3 3 3 3 3 3 6 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 总 投 资 达 1 3 ． 2 6 亿 元 的 郑 州 中 原 制 药 厂 因 盲 目 引 进 不 成 熟 的 国 外 技 术 设 备 ， 自 1 9 9 2 年 试 车 后 一 直 不 能 正 常 生 产 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 总 投 资 达 1 3 ． 2 6 亿 元 的 郑 州 中 原 制 药 厂 因 盲 目 引 进 不 成 熟 的 国 外 技 术 设 备 ， 自 1 9 9 2 年 试 车 后 一 直 不 能 正 常 生 产 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2600 2832 6598 6809 122 124 8026 123 127 783 1039 4638 6948 2336 704 1333 1169 5790 1322 1728 4683 4680 2471 6822 679 2768 4225 4638 1744 1912 2825 3318 6392 1906 8024 5632 122 130 130 123 2399 6407 6756 1400 671 4684 679 5543 3633 2382 4495 772 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2600 2832 6598 6809 122 124 8026 123 127 783 1039 4638 6948 2336 704 1333 1169 5790 1322 1728 4683 4680 2471 6822 679 2768 4225 4638 1744 1912 2825 3318 6392 1906 8024 5632 122 130 130 123 2399 6407 6756 1400 671 4684 679 5543 3633 2382 4495 772 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 6 7 7 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 6 7 7 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-2\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-2\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 在 南 斯 拉 夫 政 府 看 来 ， 造 成 上 述 恶 果 的 罪 魁 是 阿 族 非 法 武 装 科 索 沃 解 放 军 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 在 南 斯 拉 夫 政 府 看 来 ， 造 成 上 述 恶 果 的 罪 魁 是 阿 族 非 法 武 装 科 索 沃 解 放 军 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1762 1298 3172 2861 1923 3124 2424 4692 3341 8024 6863 2768 677 6835 2626 3362 4638 5389 7788 3221 7350 3184 7478 3791 3636 6163 4906 5164 3753 6237 3123 1092 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1762 1298 3172 2861 1923 3124 2424 4692 3341 8024 6863 2768 677 6835 2626 3362 4638 5389 7788 3221 7350 3184 7478 3791 3636 6163 4906 5164 3753 6237 3123 1092 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 4 5 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 7 7 7 7 7 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 4 5 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 7 7 7 7 7 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-3\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-3\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 而 且 ， 马 列 主 义 作 为 一 种 科 学 真 理 ， 它 既 不 需 要 、 也 不 应 当 强 制 人 们 去 [UNK] 宗 奉 [UNK] 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 而 且 ， 马 列 主 义 作 为 一 种 科 学 真 理 ， 它 既 不 需 要 、 也 不 应 当 强 制 人 们 去 [UNK] 宗 奉 [UNK] 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5445 684 8024 7716 1154 712 721 868 711 671 4905 4906 2110 4696 4415 8024 2124 3188 679 7444 6206 510 738 679 2418 2496 2487 1169 782 812 1343 100 2134 1938 100 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5445 684 8024 7716 1154 712 721 868 711 671 4905 4906 2110 4696 4415 8024 2124 3188 679 7444 6206 510 738 679 2418 2496 2487 1169 782 812 1343 100 2134 1938 100 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-4\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: train-4\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 不 如 此 ， 就 很 难 站 住 ， 更 不 要 说 站 在 世 界 和 时 代 的 前 列 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 不 如 此 ， 就 很 难 站 住 ， 更 不 要 说 站 在 世 界 和 时 代 的 前 列 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 679 1963 3634 8024 2218 2523 7410 4991 857 8024 3291 679 6206 6432 4991 1762 686 4518 1469 3198 807 4638 1184 1154 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 679 1963 3634 8024 2218 2523 7410 4991 857 8024 3291 679 6206 6432 4991 1762 686 4518 1469 3198 807 4638 1184 1154 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 5000 of 20864\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 5000 of 20864\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 10000 of 20864\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 10000 of 20864\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 15000 of 20864\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 15000 of 20864\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 20000 of 20864\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 20000 of 20864\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:***** Running training *****\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:***** Running training *****\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Num examples = 20864\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Num examples = 20864\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Batch size = 16\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Batch size = 16\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Num steps = 6520\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Num steps = 6520\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Skipping training since max_steps has already saved.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Skipping training since max_steps has already saved.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:training_loop marked as finished\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:training_loop marked as finished\n"],"name":"stderr"},{"output_type":"stream","text":["data_set:  [['她 说 ， 以 前 参 加 比 赛 就 是 要 为 国 争 光 ， 要 拿 世 界 冠 军 ， 赛 前 心 理 压 力 很 大 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 成 功 地 塑 造 了 许 多 性 格 各 异 、 栩 栩 如 生 的 喜 剧 形 象 ， 其 代 表 剧 目 有 《 唐 知 县 审 诰 命 》 、 《 做 文 章 》 、 《 仨 愿 意 》 等 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-PER O O O O O O O O O O O O O O O O O O O O'], ['看 来 ， 东 亚 金 融 危 机 及 其 对 世 界 经 济 的 影 响 ， 已 把 改 革 国 际 金 融 体 系 的 问 题 明 确 提 到 国 际 社 会 面 前 。', 'O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['片 中 ， 人 们 看 到 在 民 主 选 举 之 前 ， 村 民 的 心 态 是 漠 然 的 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O'], ['金 士 尧 于 1 9 3 7 年 9 月 出 生 在 江 苏 苏 州 的 一 个 中 医 世 家 。', 'B-PER I-PER I-PER O O O O O O O O O O O B-LOC I-LOC B-LOC I-LOC O O O B-LOC O O O O'], ['全 省 先 后 有 5 0 多 所 高 校 的 1 0 0 多 名 教 师 在 “ 中 心 ” 的 引 导 、 帮 助 下 撰 写 了 论 文 ， 中 心 组 织 了 学 术 水 平 较 高 的 教 师 对 其 中 2 0 0 多 篇 论 文 进 行 评 审 ， 并 提 出 修 改 意 见 。', 'O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 次 展 览 是 由 南 非 中 国 非 洲 工 程 协 会 、 南 非 金 巢 文 化 事 业 有 限 公 司 和 南 非 国 家 博 物 馆 联 合 举 办 的 。', 'O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O'], ['其 中 单 、 双 打 的 冠 军 将 分 别 获 得 3 0 0 0 元 和 2 0 0 0 元 的 奖 金 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['』 待 人 诚 恳 、 自 尊 自 信 自 强 的 焦 英 ， 也 照 样 不 能 免 俗 ， 她 对 孩 子 ， 虽 不 逼 不 骂 不 嚷 ， 但 骨 子 里 依 然 有 一 种 『 你 要 为 娘 争 气 』 的 潜 意 识 在 。', 'O O O O O O O O O O O O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 说 ， 新 美 钞 很 难 仿 冒 ， 但 任 何 技 术 都 不 可 能 做 到 绝 对 无 法 仿 冒 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['开 放 后 ， 令 朝 阳 体 育 馆 员 工 们 始 料 未 及 的 是 ， 体 育 市 场 还 真 广 阔 ， 体 育 消 费 还 真 叫 热 。', 'O O O O O B-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['我 认 为 ， 教 育 的 根 本 任 务 是 培 养 人 才 。', 'O O O O O O O O O O O O O O O O O'], ['在 一 些 地 方 和 单 位 ， 『 事 出 有 因 ， 查 无 实 据 』 的 事 情 不 少 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['中 信 欧 洲 有 限 公 司 的 一 位 业 务 经 理 说 ， 欧 元 启 动 后 ， 欧 盟 企 业 会 要 求 以 欧 元 结 算 ， 甚 至 给 一 些 优 惠 来 鼓 励 你 用 欧 元 结 算 ， 如 果 中 国 企 业 仍 然 坚 持 要 用 美 元 结 算 ， 有 的 欧 盟 企 业 可 能 就 会 放 弃 订 货 ， 或 者 同 可 以 用 欧 元 结 算 的 中 国 企 业 订 货 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O'], ['去 年 初 ， 平 原 县 委 、 县 政 府 转 变 思 路 ， 完 善 科 技 推 广 网 络 ， 在 做 给 农 民 看 上 动 脑 筋 ， 他 们 在 1 8 个 乡 镇 建 起 了 5 7 所 “ 田 间 学 校 ” ， 一 些 先 进 农 业 技 术 首 先 在 这 里 实 验 。', 'O O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['爱 尔 兰 共 和 军 于 去 年 7 月 宣 布 无 期 限 停 火 ， 并 支 持 其 政 治 组 织 新 芬 党 参 加 北 爱 和 平 谈 判 ， 为 今 年 4 月 达 成 历 史 性 和 平 协 议 创 造 了 条 件 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O'], ['北 京 是 全 国 的 首 都 ， 作 为 绝 无 仅 有 的 集 政 治 、 文 化 、 对 外 交 往 和 经 济 发 展 于 一 身 的 中 心 城 市 ， 其 城 市 的 性 质 加 之 城 市 本 身 所 拥 有 的 1 1 0 0 万 人 口 和 约 4 0 0 万 左 右 的 流 动 人 口 ， 房 价 位 居 全 国 之 首 ， 仅 从 市 场 供 求 关 系 这 一 角 度 理 解 本 应 无 可 非 议 。', 'B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['在 由 计 划 经 济 向 社 会 主 义 市 场 经 济 转 轨 的 时 期 ， 改 革 开 放 日 新 月 异 ， 民 族 地 区 和 少 数 民 族 的 发 展 突 飞 猛 进 ， 人 口 的 流 动 也 日 益 频 繁 ， 在 生 活 和 工 作 中 ， 我 们 每 个 人 都 有 可 能 接 触 到 和 少 数 民 族 相 关 的 问 题 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['克 林 顿 说 ， 美 国 支 持 多 边 金 融 机 构 向 俄 罗 斯 提 供 更 多 贷 款 ， 帮 助 俄 罗 斯 稳 定 金 融 市 场 ， 加 速 结 构 改 革 ， 实 现 经 济 增 长 ， 恢 复 外 国 投 资 商 对 俄 罗 斯 经 济 的 信 心 。', 'B-PER I-PER I-PER O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O'], ['在 社 科 院 兴 办 “ 三 产 ” 急 需 资 金 和 人 才 的 时 候 ， 朱 来 常 将 他 们 作 为 开 发 人 才 ， 推 荐 给 主 持 社 科 院 工 作 的 何 永 炎 和 分 管 行 政 、 开 发 工 作 的 副 院 长 韩 永 荣 。', 'O B-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG O O O B-PER I-PER I-PER O O O O O O O O O O O O O O B-PER I-PER I-PER O'], ['因 此 我 想 ， 中 国 人 面 对 外 国 讼 事 时 ， 要 之 又 要 的 ， 还 是 先 要 拿 出 自 信 和 勇 气 ， 敢 于 跑 到 冷 峻 的 法 律 背 后 ， 先 在 文 化 语 言 上 做 到 知 己 知 彼 。', 'O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['1 9 9 7 年 城 市 污 染 水 处 理 厂 增 加 到 1 6 0 座 ， 城 市 污 水 处 理 率 增 加 到 1 3 ． 6 ％ 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['五 月 ， 第 四 届 国 际 苏 铁 生 物 学 会 议 曾 在 攀 枝 花 召 开 。', 'O O O O O O O O O O O O O O O O O B-LOC I-LOC I-LOC O O O'], ['这 一 中 药 二 类 新 药 已 在 国 内 2 0 0 0 多 家 大 中 型 医 院 临 床 使 用 ， 被 评 价 为 目 前 国 内 外 肿 瘤 临 床 较 为 理 想 的 综 合 性 治 疗 药 。', 'O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['该 报 告 指 出 ， 在 第 二 次 世 界 大 战 期 间 ， 瑞 士 是 德 国 纳 粹 黄 金 交 易 “ 最 重 要 的 中 转 站 ” 。', 'O O O O O O O O O O O O O O O O O B-LOC I-LOC O B-LOC I-LOC O O O O O O O O O O O O O O O O'], ['他 用 手 扶 着 自 己 的 大 卡 车 说 ， 苜 蓿 草 具 有 很 高 的 经 济 价 值 ， 我 们 用 收 割 机 在 田 野 里 将 苜 蓿 草 打 成 捆 ， 运 回 库 房 等 待 出 售 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 些 现 象 ， 有 些 人 称 之 为 “ 交 学 费 ” ， 不 可 避 免 。', 'O O O O O O O O O O O O O O O O O O O O O O'], ['大 量 的 农 业 劳 动 力 需 要 转 移 ， 需 要 有 新 的 政 策 和 对 策 。', 'O O O O O O O O O O O O O O O O O O O O O O O O'], ['北 京 多 云 转 晴 1 5 ℃ ／ 2 7 ℃ 天 津 多 云 1 6 ℃ ／ 2 8 ℃ 石 家 庄 阴 转 多 云 1 6 ℃ ／ 2 7 ℃ 太 原 多 云 1 3 ℃ ／ 2 9 ℃ 呼 和 浩 特 晴 1 1 ℃ ／ 2 6 ℃ 沈 阳 小 雨 转 晴 1 3 ℃ ／ 2 7 ℃ 大 连 多 云 转 晴 1 6 ℃ ／ 2 3 ℃ 长 春 多 云 转 晴 1 4 ℃ ／ 2 4 ℃ 哈 尔 滨 多 云 转 晴 9 ℃ ／ 2 5 ℃ 上 海 晴 2 0 ℃ ／ 3 0 ℃ 南 京 雷 阵 雨 1 7 ℃ ／ 2 9 ℃ 杭 州 多 云 转 小 雨 2 0 ℃ ／ 3 1 ℃ 合 肥 多 云 1 9 ℃ ／ 2 9 ℃ 福 州 阴 转 多 云 2 2 ℃ ／ 3 0 ℃ 南 昌 多 云 转 阴 2 0 ℃ ／ 2 8 ℃ 济 南 多 云 2 3 ℃ ／ 3 0 ℃ 青 岛 多 云 转 晴 1 6 ℃ ／ 2 6 ℃ 郑 州 多 云 转 阴 1 8 ℃ ／ 2 7 ℃ 武 汉 晴 转 多 云 2 0 ℃ ／ 3 2 ℃ 长 沙 多 云 2 0 ℃ ／ 3 1 ℃ 广 州 多 云 转 小 雨 2 5 ℃ ／ 3 2 ℃ 南 宁 小 雨 2 5 ℃ ／ 3 2 ℃ 海 口 多 云 2 6 ℃ ／ 3 5 ℃ 成 都 阴 转 雷 阵 雨 2 2 ℃ ／ 3 0 ℃ 重 庆 多 云 转 阴 2 2 ℃ ／ 3 2 ℃ 贵 阳 小 雨 转 多 云 1 8 ℃ ／ 2 9 ℃ 昆 明 多 云 转 晴 1 7 ℃ ／ 2 6 ℃ 拉 萨 多 云 6 ℃ ／ 2 3 ℃ 西 安 小 雨 1 6 ℃ ／ 2 5 ℃ 兰 州 晴 转 多 云 1 3 ℃ ／ 2 9 ℃ 西 宁 多 云 1 0 ℃ ／ 2 2 ℃ 银 川 多 云 转 阴 1 4 ℃ ／ 2 3 ℃ 乌 鲁 木 齐 小 雨 转 多 云 3 ℃ ／ 8 ℃ 台 北 阴 2 3 ℃ ／ 2 9 ℃ 香 港 小 雨 2 4 ℃ ／ 3 0 ℃ 澳 门 小 雨 2 4 ℃ ／ 3 0 ℃ 东 京 多 云 1 6 ℃ ／ 2 4 ℃ 曼 谷 雷 阵 雨 2 7 ℃ ／ 3 1 ℃ 悉 尼 晴 1 5 ℃ ／ 2 2 ℃ 卡 拉 奇 晴 2 6 ℃ ／ 3 4 ℃ 开 罗 晴 1 9 ℃ ／ 3 0 ℃ 莫 斯 科 小 雨 9 ℃ ／ 1 8 ℃ 法 兰 克 福 晴 9 ℃ ／ 2 4 ℃ 巴 黎 多 云 1 4 ℃ ／ 2 4 ℃ 伦 敦 多 云 转 阴 1 3 ℃ ／ 2 3 ℃ 纽 约 小 雨 1 2 ℃ ／ 2 0 ℃', 'B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O'], ['本 报 东 京 6 月 1 1 日 电 受 日 本 金 融 体 系 信 任 危 机 和 亚 洲 金 融 市 场 汇 市 、 股 市 下 跌 的 影 响 ， 东 京 金 融 市 场 日 元 汇 率 、 股 票 价 格 全 面 下 跌 。', 'O O B-LOC I-LOC O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O'], ['图 为 北 京 王 府 井 新 东 安 市 场 广 场 上 ， 残 疾 人 在 向 法 律 工 作 者 们 咨 询 法 律 问 题 。', 'O O B-LOC I-LOC B-LOC I-LOC I-LOC B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O'], ['住 户 的 生 活 用 电 于 是 便 没 了 着 落 。', 'O O O O O O O O O O O O O O O'], ['张 吉 龙 首 先 代 表 中 国 足 协 说 ， 我 们 衷 心 祝 贺 布 拉 特 先 生 当 选 国 际 足 联 主 席 ， 同 时 ， 祝 愿 他 为 促 进 世 界 足 球 的 发 展 作 出 新 贡 献 。', 'B-PER I-PER I-PER O O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O O B-PER I-PER I-PER O O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 时 ， 小 伙 子 信 誓 旦 旦 地 说 ： “ 那 好 ， 我 们 一 起 到 入 口 处 去 ， 等 你 的 同 事 进 去 后 ， 你 再 付 钱 。 ”', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 说 ， 中 国 是 一 个 伟 大 的 国 家 ， 在 改 革 和 发 展 中 找 到 了 一 条 正 确 的 发 展 道 路 ， 成 功 实 现 了 计 划 与 市 场 的 结 合 ， 实 现 了 经 济 的 快 速 发 展 ， 极 大 地 改 善 了 人 民 的 生 活 。', 'O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['不 久 前 ， 我 从 国 内 一 家 报 纸 上 读 到 有 关 国 内 某 名 牌 v c d 的 报 道 ， 说 是 此 机 型 率 先 采 用 了 飞 利 浦 伺 服 机 芯 、 美 国 c － c u b e 解 码 电 路 、 日 本 雅 马 哈 数 字 卡 拉 o k 、 夏 普 四 端 稳 压 电 路 等 技 术 或 部 件 ， 除 此 之 外 ， 还 有 为 生 产 v c d 从 国 外 引 进 的 许 多 名 牌 仪 器 和 设 备 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['管 理 局 方 面 承 认 ， 目 前 黑 车 执 法 和 处 罚 的 力 度 不 够 ， 今 后 需 加 强 联 合 执 法 。', 'B-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['回 想 起 来 ， 以 往 许 多 日 子 是 将 就 的 日 子 ， 是 理 想 与 现 实 之 间 不 断 的 妥 协 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 种 将 历 史 资 料 与 历 史 人 物 回 忆 ， 将 第 一 人 称 与 第 三 人 称 有 机 融 为 一 书 者 ， 亦 可 视 为 党 史 研 究 中 的 先 行 体 例 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['老 板 们 很 清 楚 ： 一 种 商 机 出 现 ， 必 有 其 制 高 点 。', 'O O O O O O O O O O O O O O O O O O O O O'], ['中 美 两 国 有 关 公 司 和 机 构 今 天 下 午 在 人 民 大 会 堂 举 行 大 型 签 字 仪 式 ， 共 签 订 了 总 金 额 近 2 0 亿 美 元 的 7 个 重 要 经 贸 合 作 项 目 的 合 同 或 协 议 。', 'B-LOC B-LOC O O O O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 里 的 乡 镇 企 业 因 其 起 步 早 、 发 展 快 、 规 模 大 、 效 益 好 而 被 总 结 为 “ 苏 南 模 式 ” 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC O O O O O'], ['分 工 ， 各 有 各 的 责 任 ； 合 作 ， 正 副 经 理 之 间 ， 全 厂 的 事 ， 不 管 由 谁 分 管 ， 也 不 管 你 有 什 么 事 找 到 谁 ， 绝 不 会 把 你 推 给 第 二 个 人 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['单 位 的 电 灯 ， 不 少 是 开 时 容 易 关 时 难 ， 人 走 灯 仍 亮 ， 天 亮 灯 不 灭 ； 企 业 的 物 资 管 理 混 乱 ， 大 手 大 脚 ， 不 计 工 本 ， 有 用 的 零 配 件 、 原 材 料 ， 在 垃 圾 堆 里 比 比 皆 是 ， 造 就 了 不 少 『 垃 圾 暴 发 户 』 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['旧 中 国 经 济 统 计 资 料 既 缺 少 又 散 乱 ， 给 计 量 研 究 造 成 了 极 大 的 困 难 。', 'O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['巴 西 队 与 挪 威 队 一 役 ， 谁 都 认 为 这 场 比 赛 挪 威 人 死 定 了 。', 'B-ORG I-ORG I-ORG O B-ORG I-ORG I-ORG O O O O O O O O O O O B-LOC I-LOC O O O O O'], ['韩 国 的 金 泽 洙 苦 战 五 局 以 三 比 二 战 胜 比 利 时 的 卡 勃 莱 拉 ， 闯 入 决 赛 ， 并 以 三 比 一 的 成 绩 夺 得 冠 军 。', 'B-LOC I-LOC O B-PER I-PER I-PER O O O O O O O O O O B-LOC I-LOC I-LOC O B-PER I-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O'], ['您 看 ， 一 桌 饭 菜 ， 加 上 酒 水 ， 少 说 也 得 五 六 百 元 ； 再 加 工 作 人 员 、 记 者 ， 连 吃 带 喝 不 下 一 万 多 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['建 立 汇 率 、 利 率 风 险 防 范 意 识 ， 加 强 债 务 管 理 ， 对 企 业 而 言 不 仅 是 必 要 的 ， 而 且 变 得 越 来 越 紧 迫 了 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['当 务 之 急 是 要 强 化 管 理 ， 全 力 以 赴 堵 塞 税 收 征 管 漏 洞 。', 'O O O O O O O O O O O O O O O O O O O O O O O O']]\n","INFO:tensorflow:Writing example 0 of 2318\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 2318\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 她 说 ， 以 前 参 加 比 赛 就 是 要 为 国 争 光 ， 要 拿 世 界 冠 军 ， 赛 前 心 理 压 力 很 大 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 她 说 ， 以 前 参 加 比 赛 就 是 要 为 国 争 光 ， 要 拿 世 界 冠 军 ， 赛 前 心 理 压 力 很 大 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1961 6432 8024 809 1184 1346 1217 3683 6612 2218 3221 6206 711 1744 751 1045 8024 6206 2897 686 4518 1094 1092 8024 6612 1184 2552 4415 1327 1213 2523 1920 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1961 6432 8024 809 1184 1346 1217 3683 6612 2218 3221 6206 711 1744 751 1045 8024 6206 2897 686 4518 1094 1092 8024 6612 1184 2552 4415 1327 1213 2523 1920 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 他 成 功 地 塑 造 了 许 多 性 格 各 异 、 栩 栩 如 生 的 喜 剧 形 象 ， 其 代 表 剧 目 有 《 唐 知 县 审 诰 命 》 、 《 做 文 章 》 、 《 仨 愿 意 》 等 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 他 成 功 地 塑 造 了 许 多 性 格 各 异 、 栩 栩 如 生 的 喜 剧 形 象 ， 其 代 表 剧 目 有 《 唐 知 县 审 诰 命 》 、 《 做 文 章 》 、 《 仨 愿 意 》 等 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 800 2768 1216 1765 1848 6863 749 6387 1914 2595 3419 1392 2460 510 3414 3414 1963 4495 4638 1599 1196 2501 6496 8024 1071 807 6134 1196 4680 3300 517 1538 4761 1344 2144 6429 1462 518 510 517 976 3152 4995 518 510 517 810 2703 2692 518 5023 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 800 2768 1216 1765 1848 6863 749 6387 1914 2595 3419 1392 2460 510 3414 3414 1963 4495 4638 1599 1196 2501 6496 8024 1071 807 6134 1196 4680 3300 517 1538 4761 1344 2144 6429 1462 518 510 517 976 3152 4995 518 510 517 810 2703 2692 518 5023 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-2\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-2\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 看 来 ， 东 亚 金 融 危 机 及 其 对 世 界 经 济 的 影 响 ， 已 把 改 革 国 际 金 融 体 系 的 问 题 明 确 提 到 国 际 社 会 面 前 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 看 来 ， 东 亚 金 融 危 机 及 其 对 世 界 经 济 的 影 响 ， 已 把 改 革 国 际 金 融 体 系 的 问 题 明 确 提 到 国 际 社 会 面 前 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4692 3341 8024 691 762 7032 6084 1314 3322 1350 1071 2190 686 4518 5307 3845 4638 2512 1510 8024 2347 2828 3121 7484 1744 7354 7032 6084 860 5143 4638 7309 7579 3209 4802 2990 1168 1744 7354 4852 833 7481 1184 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4692 3341 8024 691 762 7032 6084 1314 3322 1350 1071 2190 686 4518 5307 3845 4638 2512 1510 8024 2347 2828 3121 7484 1744 7354 7032 6084 860 5143 4638 7309 7579 3209 4802 2990 1168 1744 7354 4852 833 7481 1184 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 4 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 4 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-3\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-3\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 片 中 ， 人 们 看 到 在 民 主 选 举 之 前 ， 村 民 的 心 态 是 漠 然 的 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 片 中 ， 人 们 看 到 在 民 主 选 举 之 前 ， 村 民 的 心 态 是 漠 然 的 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4275 704 8024 782 812 4692 1168 1762 3696 712 6848 715 722 1184 8024 3333 3696 4638 2552 2578 3221 4030 4197 4638 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4275 704 8024 782 812 4692 1168 1762 3696 712 6848 715 722 1184 8024 3333 3696 4638 2552 2578 3221 4030 4197 4638 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-4\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: dev-4\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 金 士 尧 于 1 9 3 7 年 9 月 出 生 在 江 苏 苏 州 的 一 个 中 医 世 家 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 金 士 尧 于 1 9 3 7 年 9 月 出 生 在 江 苏 苏 州 的 一 个 中 医 世 家 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 7032 1894 2216 754 122 130 124 128 2399 130 3299 1139 4495 1762 3736 5722 5722 2336 4638 671 702 704 1278 686 2157 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 7032 1894 2216 754 122 130 124 128 2399 130 3299 1139 4495 1762 3736 5722 5722 2336 4638 671 702 704 1278 686 2157 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 8 9 9 3 3 3 3 3 3 3 3 3 3 3 4 5 4 5 3 3 3 4 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 8 9 9 3 3 3 3 3 3 3 3 3 3 3 4 5 4 5 3 3 3 4 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:***** Running evaluation *****\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:***** Running evaluation *****\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Num examples = 2318\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Num examples = 2318\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Batch size = 16\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Batch size = 16\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-3af1d9d59918>:371: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-3af1d9d59918>:371: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-3af1d9d59918>:358: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-3af1d9d59918>:358: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running eval on CPU\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running eval on CPU\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Features ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Features ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = input_ids, shape = (?, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = input_ids, shape = (?, 128)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = input_mask, shape = (?, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = input_mask, shape = (?, 128)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = label_ids, shape = (?, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = label_ids, shape = (?, 128)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:492: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:492: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:673: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:673: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:**** Trainable Variables ****\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:**** Trainable Variables ****\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = output_weights:0, shape = (11, 768)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = output_weights:0, shape = (11, 768)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = output_bias:0, shape = (11,)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = output_bias:0, shape = (11,)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = loss/dense/kernel:0, shape = (768, 11)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = loss/dense/kernel:0, shape = (768, 11)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = loss/dense/bias:0, shape = (11,)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = loss/dense/bias:0, shape = (11,)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  name = loss/transitions:0, shape = (11, 11)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  name = loss/transitions:0, shape = (11, 11)\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/tf_metrics.py:151: The name tf.diag_part is deprecated. Please use tf.linalg.tensor_diag_part instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/tf_metrics.py:151: The name tf.diag_part is deprecated. Please use tf.linalg.tensor_diag_part instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/tf_metrics.py:139: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/bert-ner/BERT-silkrode-sample-ner/model_train/tf_metrics.py:139: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-11-21T23:30:20Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-11-21T23:30:20Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./output/model.ckpt-13040\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./output/model.ckpt-13040\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-11-21-23:31:13\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-11-21-23:31:13\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 13040: eval_f = 0.7191007, eval_precision = 0.5988906, eval_recall = 0.9756849, global_step = 13040, loss = 40.63298\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 13040: eval_f = 0.7191007, eval_precision = 0.5988906, eval_recall = 0.9756849, global_step = 13040, loss = 40.63298\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13040: ./output/model.ckpt-13040\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13040: ./output/model.ckpt-13040\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:evaluation_loop marked as finished\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:evaluation_loop marked as finished\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:***** Eval results *****\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:***** Eval results *****\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  eval_f = 0.7191007\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  eval_f = 0.7191007\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  eval_precision = 0.5988906\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  eval_precision = 0.5988906\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  eval_recall = 0.9756849\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  eval_recall = 0.9756849\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  global_step = 13040\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  global_step = 13040\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  loss = 40.63298\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  loss = 40.63298\n"],"name":"stderr"},{"output_type":"stream","text":["data_set:  [['王 玉 梅 是 内 蒙 古 乌 达 矿 务 局 职 工 ， 1 9 9 6 年 1 月 主 动 要 求 下 了 岗 。', 'B-PER I-PER I-PER O B-LOC I-LOC I-LOC B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O'], ['今 天 上 午 ， 国 家 林 业 局 根 据 火 场 前 线 的 请 求 ， 紧 急 调 拨 一 百 台 风 力 灭 火 机 和 一 百 台 水 枪 运 往 火 场 。', 'O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['国 家 税 务 总 局 要 求 全 国 税 务 系 统 各 级 领 导 ， 要 务 必 认 识 到 今 年 组 织 收 入 工 作 的 特 殊 性 和 艰 巨 性 ， 切 实 转 变 作 风 ， 提 高 效 率 ， 保 证 今 年 工 作 目 标 的 实 现 。', 'B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['强 调 依 法 治 国 以 及 法 治 与 人 治 的 根 本 对 立 ， 是 法 治 概 念 具 有 的 鲜 明 的 本 质 特 征 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 们 唱 着 保 育 院 院 歌 ， 进 入 这 一 个 个 新 家 ， 结 束 了 流 浪 行 乞 的 日 子 ， 重 新 得 到 了 母 亲 温 馨 胸 脯 的 抚 慰 和 甘 甜 乳 汁 的 滋 养 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 不 仅 表 现 在 她 始 终 如 一 地 深 爱 着 自 己 当 乡 下 郎 中 的 丈 夫 ， 在 长 期 的 农 村 生 活 中 ， 李 燕 玲 还 和 农 民 结 下 了 深 厚 的 感 情 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O'], ['企 业 要 搞 市 场 研 究 ， 确 定 投 资 方 向 ， 就 必 须 找 社 会 咨 询 机 构 ， 以 及 财 务 顾 问 、 法 律 顾 问 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['当 然 ， 选 举 中 还 存 在 不 少 有 待 解 决 的 问 题 。', 'O O O O O O O O O O O O O O O O O O O'], ['这 一 天 被 认 为 是 联 合 国 维 和 行 动 开 始 之 日 。', 'O O O O O O O B-ORG I-ORG I-ORG O O O O O O O O O'], ['对 外 友 协 会 长 齐 怀 远 在 宴 会 上 说 ， 中 国 同 阿 曼 的 友 好 关 系 源 远 流 长 。', 'B-ORG I-ORG I-ORG I-ORG O O B-PER I-PER I-PER O O O O O O B-LOC I-LOC O B-LOC I-LOC O O O O O O O O O O'], ['如 果 领 导 干 部 有 不 良 作 风 ， 形 成 不 良 形 象 ， 就 会 在 “ 互 动 ” 中 恶 性 循 环 ， 错 误 的 思 想 被 姑 息 ， 不 正 之 风 被 助 长 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['巴 基 斯 坦 总 理 纳 瓦 兹 · 谢 里 夫 今 天 在 这 里 说 ， 巴 将 继 续 为 国 际 社 会 实 现 核 裁 军 和 不 进 行 核 扩 散 的 目 标 作 出 自 己 的 努 力 。', 'B-LOC I-LOC I-LOC I-LOC O O B-PER I-PER I-PER I-PER I-PER I-PER I-PER O O O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['加 上 亚 洲 经 济 增 速 减 缓 的 因 素 ， 今 年 世 界 经 济 增 长 率 将 从 去 年 的 3 · 2 ％ 下 降 一 个 百 分 点 ， 今 年 世 界 贸 易 增 长 将 从 去 年 的 9 ％ 下 降 半 个 百 分 点 。', 'O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['中 国 游 泳 界 高 级 官 员 今 天 在 这 里 称 ， 中 国 将 采 取 比 国 际 通 行 的 制 裁 原 则 更 严 厉 的 反 兴 奋 剂 措 施 。', 'B-LOC I-LOC O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 的 话 不 无 道 理 ， 会 上 呈 现 的 特 点 和 倾 向 ， 可 能 在 很 大 程 度 上 影 响 “ 未 来 欧 洲 ” 的 走 向 和 进 程 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O'], ['山 村 ， 也 给 人 们 带 来 无 限 的 愉 悦 。', 'O O O O O O O O O O O O O O O'], ['她 在 副 总 统 选 举 中 获 得 1 2 0 0 多 万 张 选 票 ， 遥 遥 领 先 于 其 他 8 位 候 选 人 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['据 悉 ： “ 春 蕾 计 划 ” 自 1 9 9 2 年 实 施 以 来 ， 已 累 计 救 助 6 0 万 人 次 失 学 女 童 重 返 校 园 ， 为 辅 助 国 家 发 展 基 础 教 育 作 出 了 有 益 的 贡 献 ， 产 生 了 良 好 的 社 会 反 响 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 们 是 一 个 在 德 国 猖 狂 活 动 的 贩 毒 集 团 中 的 首 要 分 子 。', 'O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O'], ['北 京 多 云 1 8 ℃ ／ 3 2 ℃ 天 津 阴 转 小 雨 1 9 ℃ ／ 2 9 ℃ 石 家 庄 多 云 转 阴 2 1 ℃ ／ 3 1 ℃ 太 原 小 雨 1 5 ℃ ／ 2 4 ℃ 呼 和 浩 特 多 云 转 小 雨 1 3 ℃ ／ 2 6 ℃ 沈 阳 小 雨 转 多 云 1 6 ℃ ／ 2 7 ℃ 大 连 晴 1 6 ℃ ／ 2 2 ℃ 长 春 雷 阵 雨 1 2 ℃ ／ 2 1 ℃ 哈 尔 滨 晴 转 多 云 1 2 ℃ ／ 2 5 ℃ 上 海 小 雨 2 0 ℃ ／ 2 5 ℃ 南 京 中 雨 2 0 ℃ ／ 2 6 ℃ 杭 州 中 雨 2 0 ℃ ／ 2 6 ℃ 合 肥 大 雨 转 小 雨 1 9 ℃ ／ 2 5 ℃ 福 州 中 雨 转 小 雨 2 2 ℃ ／ 2 6 ℃ 南 昌 中 雨 转 大 雨 1 9 ℃ ／ 2 4 ℃ 济 南 多 云 2 3 ℃ ／ 3 2 ℃ 青 岛 多 云 转 阴 1 6 ℃ ／ 2 2 ℃ 郑 州 雷 阵 雨 转 多 云 2 0 ℃ ／ 2 9 ℃ 武 汉 小 雨 转 多 云 2 3 ℃ ／ 2 8 ℃ 长 沙 小 雨 2 0 ℃ ／ 2 8 ℃ 广 州 多 云 转 小 雨 2 6 ℃ ／ 3 1 ℃ 南 宁 小 雨 2 5 ℃ ／ 3 2 ℃ 海 口 多 云 转 雷 阵 雨 2 6 ℃ ／ 3 4 ℃ 成 都 阴 转 多 云 1 9 ℃ ／ 2 5 ℃ 重 庆 阴 转 多 云 2 2 ℃ ／ 2 8 ℃ 贵 阳 小 雨 转 阴 1 7 ℃ ／ 2 3 ℃ 昆 明 小 雨 1 7 ℃ ／ 2 4 ℃ 拉 萨 多 云 1 3 ℃ ／ 2 8 ℃ 西 安 小 雨 转 多 云 1 6 ℃ ／ 2 7 ℃ 兰 州 多 云 1 4 ℃ ／ 2 7 ℃ 西 宁 多 云 9 ℃ ／ 2 2 ℃ 银 川 多 云 转 晴 1 5 ℃ ／ 2 6 ℃ 乌 鲁 木 齐 小 雨 1 1 ℃ ／ 1 8 ℃ 台 北 小 雨 2 3 ℃ ／ 2 9 ℃ 香 港 小 雨 2 5 ℃ ／ 2 8 ℃ 澳 门 小 雨 2 5 ℃ ／ 2 9 ℃ 东 京 多 云 1 7 ℃ ／ 2 3 ℃ 曼 谷 小 雨 2 6 ℃ ／ 3 3 ℃ 悉 尼 多 云 转 阴 1 3 ℃ ／ 1 9 ℃ 卡 拉 奇 多 云 2 6 ℃ ／ 3 3 ℃ 开 罗 晴 2 1 ℃ ／ 3 4 ℃ 莫 斯 科 晴 转 多 云 1 8 ℃ ／ 3 0 ℃ 法 兰 克 福 小 雨 转 多 云 1 4 ℃ ／ 2 1 ℃ 巴 黎 多 云 1 3 ℃ ／ 2 0 ℃ 伦 敦 阴 1 1 ℃ ／ 1 8 ℃ 纽 约 多 云 转 阴 1 3 ℃ ／ 2 2 ℃', 'B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O'], ['只 有 高 中 文 凭 的 王 建 新 被 破 格 录 用 了 。', 'O O O O O O O B-PER I-PER I-PER O O O O O O O'], ['为 了 做 到 为 每 一 个 青 工 创 造 就 业 机 会 ， 各 地 团 组 织 通 过 依 托 团 内 活 动 阵 地 、 广 泛 联 络 社 会 办 学 单 位 、 委 托 用 人 单 位 培 训 等 方 式 ， 大 力 开 展 下 岗 青 工 培 训 工 作 ， 受 训 人 数 占 下 岗 青 工 总 人 数 的 9 6 ％ 以 上 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['早 在 4 月 份 ， 办 事 处 就 成 立 了 1 2 人 的 防 灾 防 损 小 组 ， 对 承 保 客 户 进 行 了 逐 一 排 查 ， 对 3 6 0 多 户 地 处 洪 灾 区 的 客 户 发 出 了 书 面 的 防 灾 防 损 通 知 书 ， 组 织 业 务 员 分 头 上 门 进 行 防 灾 防 损 指 导 ， 为 客 户 制 订 防 灾 防 损 措 施 方 案 。', 'O O O O O O O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['我 一 看 ， 这 张 票 的 原 价 比 下 午 那 张 高 ， 为 3 5 0 法 郎 ， 而 他 的 出 价 比 下 午 还 低 2 0 0 法 郎 ， 就 更 不 信 了 ： “ 假 的 ！ ”', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['我 国 已 经 决 定 修 建 时 速 2 5 0 — 3 0 0 公 里 的 京 沪 高 速 客 运 专 线 ， 已 经 着 手 研 制 摆 式 列 车 ， 也 已 开 始 进 行 超 导 磁 浮 列 车 的 研 究 。', 'O O O O O O O O O O O O O O O O O O O O B-LOC B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['菲 律 宾 的 选 举 法 规 定 得 票 最 多 的 为 获 胜 者 。', 'B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O'], ['后 三 人 集 资 2 ． 6 万 元 ， 那 时 水 泥 紧 俏 ， 一 年 净 赚 1 0 万 元 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 似 乎 意 味 着 我 的 创 作 道 路 上 一 个 新 的 开 始 。', 'O O O O O O O O O O O O O O O O O O O O'], ['向 山 区 市 县 赠 送 文 化 艺 术 上 山 下 乡 专 用 车 ， 是 广 东 “ 山 区 文 化 建 设 工 程 ” 全 面 启 动 的 第 一 项 措 施 。', 'O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O'], ['由 于 基 础 设 施 具 有 建 设 周 期 长 的 特 点 ， 如 果 我 们 现 在 不 加 快 发 展 ， 将 来 就 会 形 成 基 础 产 业 瓶 颈 制 约 ， 影 响 国 民 经 济 持 续 稳 定 发 展 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['可 是 ， 对 消 费 者 来 说 ， 不 知 产 品 如 何 使 用 ， 或 者 难 以 判 断 如 何 使 用 ， 于 消 费 者 于 企 业 都 不 利 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['韩 国 汉 城 股 市 综 合 指 数 自 本 月 4 日 跌 破 4 0 0 点 之 后 ， 渐 呈 下 降 趋 势 ， 4 日 至 1 1 日 1 周 间 下 跌 了 3 0 余 点 。', 'B-LOC I-LOC B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['汉 纳 说 ， 未 来 两 天 他 们 将 再 派 两 架 飞 机 向 伊 拉 克 运 送 救 援 药 品 和 医 疗 器 械 。', 'B-PER I-PER O O O O O O O O O O O O O O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O'], ['美 国 技 术 、 商 品 和 文 化 产 品 源 源 涌 入 中 国 。', 'B-LOC I-LOC O O O O O O O O O O O O O O B-LOC I-LOC O'], ['在 和 黑 人 同 胞 的 接 触 中 ， 他 亲 身 体 会 到 他 们 生 活 的 艰 辛 ， 于 是 暗 下 决 心 ， 一 定 要 为 改 变 黑 人 的 窘 迫 境 况 做 点 事 情 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['印 象 四 ： 欧 洲 坚 持 英 式 打 法 的 球 队 ， 如 苏 格 兰 、 挪 威 、 丹 麦 、 奥 地 利 等 队 已 明 显 跟 不 上 当 今 世 界 足 坛 发 展 的 潮 流 ， 他 们 只 能 胸 无 大 志 地 去 争 取 小 组 出 线 即 心 满 意 足 。', 'O O O O B-LOC I-LOC O O B-LOC O O O O O O O O B-ORG I-ORG I-ORG O B-ORG I-ORG O B-ORG I-ORG O B-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['个 人 住 房 在 3 — 5 年 贷 款 利 率 基 础 上 适 自 营 贷 款 当 上 浮 ， 上 浮 幅 度 最 高 不 得 超 过 5 ％', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['去 年 全 国 保 龄 球 锦 标 赛 男 女 全 能 的 前 2 2 名 选 手 有 资 格 参 赛 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['同 美 国 队 相 比 ， 俄 罗 斯 队 的 防 守 讲 求 整 体 配 合 ， 协 防 意 识 强 ， 注 重 根 据 不 同 的 对 手 、 不 同 的 情 形 不 断 变 换 防 守 方 式 。', 'O B-ORG I-ORG I-ORG O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['新 栽 树 木 主 要 是 白 杨 ， 还 有 法 国 梧 桐 、 南 美 花 梨 木 、 椴 树 和 蓝 花 楹 等 。', 'O O O O O O O O O O O O B-LOC I-LOC O O O B-LOC I-LOC O O O O O O O O O O O O'], ['展 出 的 产 品 有 奔 驰 、 宝 马 、 大 众 等 2 3 家 世 界 知 名 品 牌 的 整 车 1 3 0 多 辆 、 国 产 车 1 6 0 多 辆 ， 以 及 汽 车 零 部 件 、 加 工 制 造 设 备 、 检 测 设 备 。', 'O O O O O O B-ORG I-ORG O B-ORG I-ORG O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['他 说 ： “ 会 议 的 直 接 目 的 是 考 虑 通 过 哪 些 途 径 来 缓 解 印 巴 之 间 的 紧 张 局 面 ， 采 取 哪 些 办 法 来 防 止 类 似 过 去 几 天 、 几 周 之 内 出 现 的 挑 衅 性 的 举 动 。 ”', 'O O O O O O O O O O O O O O O O O O O O O O O B-LOC B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 两 种 提 价 行 为 ， 实 际 上 是 出 版 社 为 维 护 自 身 利 益 而 采 取 的 措 施 ， 它 不 能 充 分 解 释 图 书 定 价 过 高 这 一 问 题 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['阿 莱 曼 宣 布 ， 他 将 于 1 2 日 向 调 查 这 一 案 件 的 法 官 作 证 。', 'B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O'], ['以 上 种 种 问 题 ， 都 暴 露 出 执 法 部 门 的 管 理 漏 洞 。', 'O O O O O O O O O O O O O O O O O O O O O'], ['他 摸 了 摸 怀 里 的 干 粮 袋 ， 掏 出 了 两 个 窝 窝 头 。', 'O O O O O O O O O O O O O O O O O O O O'], ['今 年 爱 眼 日 的 主 题 是 “ 预 防 眼 外 伤 ” 。', 'O O O O O O O O O O O O O O O O O'], ['本 报 曼 谷 6 月 1 1 日 电 记 者 成 元 生 报 道 ： 泰 国 总 理 川 · 立 派 1 0 日 主 持 召 开 促 进 投 资 委 员 会 会 议 ， 制 定 7 项 措 施 以 吸 引 外 资 。', 'O O B-LOC I-LOC O O O O O O O O B-PER I-PER I-PER O O O B-LOC I-LOC O O B-PER I-PER I-PER I-PER O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O'], ['因 为 单 从 目 前 最 新 世 界 排 名 上 看 ， 孙 俊 排 第 二 、 罗 毅 刚 排 第 三 、 董 炯 则 排 在 第 五 。', 'O O O O O O O O O O O O O O O B-PER I-PER O O O O B-PER I-PER I-PER O O O O B-PER I-PER O O O O O O'], ['穆 巴 拉 克 表 示 ， 埃 及 将 致 力 调 解 厄 、 埃 塞 两 国 的 武 装 冲 突 ， 以 尽 早 实 现 两 国 就 边 境 争 端 举 行 谈 判 。', 'B-PER I-PER I-PER I-PER O O O B-LOC I-LOC O O O O O B-LOC O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O']]\n","INFO:tensorflow:Writing example 0 of 1000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 王 玉 梅 是 内 蒙 古 乌 达 矿 务 局 职 工 ， 1 9 9 6 年 1 月 主 动 要 求 下 了 岗 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 王 玉 梅 是 内 蒙 古 乌 达 矿 务 局 职 工 ， 1 9 9 6 年 1 月 主 动 要 求 下 了 岗 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4374 4373 3449 3221 1079 5885 1367 723 6809 4771 1218 2229 5466 2339 8024 122 130 130 127 2399 122 3299 712 1220 6206 3724 678 749 2266 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4374 4373 3449 3221 1079 5885 1367 723 6809 4771 1218 2229 5466 2339 8024 122 130 130 127 2399 122 3299 712 1220 6206 3724 678 749 2266 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 8 9 9 3 4 5 5 6 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 8 9 9 3 4 5 5 6 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 今 天 上 午 ， 国 家 林 业 局 根 据 火 场 前 线 的 请 求 ， 紧 急 调 拨 一 百 台 风 力 灭 火 机 和 一 百 台 水 枪 运 往 火 场 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 今 天 上 午 ， 国 家 林 业 局 根 据 火 场 前 线 的 请 求 ， 紧 急 调 拨 一 百 台 风 力 灭 火 机 和 一 百 台 水 枪 运 往 火 场 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 791 1921 677 1286 8024 1744 2157 3360 689 2229 3418 2945 4125 1767 1184 5296 4638 6435 3724 8024 5165 2593 6444 2884 671 4636 1378 7599 1213 4127 4125 3322 1469 671 4636 1378 3717 3366 6817 2518 4125 1767 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 791 1921 677 1286 8024 1744 2157 3360 689 2229 3418 2945 4125 1767 1184 5296 4638 6435 3724 8024 5165 2593 6444 2884 671 4636 1378 7599 1213 4127 4125 3322 1469 671 4636 1378 3717 3366 6817 2518 4125 1767 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 6 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 6 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-2\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-2\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 国 家 税 务 总 局 要 求 全 国 税 务 系 统 各 级 领 导 ， 要 务 必 认 识 到 今 年 组 织 收 入 工 作 的 特 殊 性 和 艰 巨 性 ， 切 实 转 变 作 风 ， 提 高 效 率 ， 保 证 今 年 工 作 目 标 的 实 现 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 国 家 税 务 总 局 要 求 全 国 税 务 系 统 各 级 领 导 ， 要 务 必 认 识 到 今 年 组 织 收 入 工 作 的 特 殊 性 和 艰 巨 性 ， 切 实 转 变 作 风 ， 提 高 效 率 ， 保 证 今 年 工 作 目 标 的 实 现 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1744 2157 4925 1218 2600 2229 6206 3724 1059 1744 4925 1218 5143 5320 1392 5277 7566 2193 8024 6206 1218 2553 6371 6399 1168 791 2399 5299 5302 3119 1057 2339 868 4638 4294 3654 2595 1469 5680 2342 2595 8024 1147 2141 6760 1359 868 7599 8024 2990 7770 3126 4372 8024 924 6395 791 2399 2339 868 4680 3403 4638 2141 4385 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1744 2157 4925 1218 2600 2229 6206 3724 1059 1744 4925 1218 5143 5320 1392 5277 7566 2193 8024 6206 1218 2553 6371 6399 1168 791 2399 5299 5302 3119 1057 2339 868 4638 4294 3654 2595 1469 5680 2342 2595 8024 1147 2141 6760 1359 868 7599 8024 2990 7770 3126 4372 8024 924 6395 791 2399 2339 868 4680 3403 4638 2141 4385 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 6 7 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 6 7 7 7 7 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-3\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-3\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 强 调 依 法 治 国 以 及 法 治 与 人 治 的 根 本 对 立 ， 是 法 治 概 念 具 有 的 鲜 明 的 本 质 特 征 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 强 调 依 法 治 国 以 及 法 治 与 人 治 的 根 本 对 立 ， 是 法 治 概 念 具 有 的 鲜 明 的 本 质 特 征 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2487 6444 898 3791 3780 1744 809 1350 3791 3780 680 782 3780 4638 3418 3315 2190 4989 8024 3221 3791 3780 3519 2573 1072 3300 4638 7831 3209 4638 3315 6574 4294 2519 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2487 6444 898 3791 3780 1744 809 1350 3791 3780 680 782 3780 4638 3418 3315 2190 4989 8024 3221 3791 3780 3519 2573 1072 3300 4638 7831 3209 4638 3315 6574 4294 2519 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-4\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: test-4\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 他 们 唱 着 保 育 院 院 歌 ， 进 入 这 一 个 个 新 家 ， 结 束 了 流 浪 行 乞 的 日 子 ， 重 新 得 到 了 母 亲 温 馨 胸 脯 的 抚 慰 和 甘 甜 乳 汁 的 滋 养 。\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: 他 们 唱 着 保 育 院 院 歌 ， 进 入 这 一 个 个 新 家 ， 结 束 了 流 浪 行 乞 的 日 子 ， 重 新 得 到 了 母 亲 温 馨 胸 脯 的 抚 慰 和 甘 甜 乳 汁 的 滋 养 。\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 800 812 1548 4708 924 5509 7368 7368 3625 8024 6822 1057 6821 671 702 702 3173 2157 8024 5310 3338 749 3837 3857 6121 737 4638 3189 2094 8024 7028 3173 2533 1168 749 3678 779 3946 7678 5541 5563 4638 2836 2720 1469 4491 4494 745 3723 4638 3996 1075 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 800 812 1548 4708 924 5509 7368 7368 3625 8024 6822 1057 6821 671 702 702 3173 2157 8024 5310 3338 749 3837 3857 6121 737 4638 3189 2094 8024 7028 3173 2533 1168 749 3678 779 3946 7678 5541 5563 4638 2836 2720 1469 4491 4494 745 3723 4638 3996 1075 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label_ids: 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:***** Running prediction*****\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:***** Running prediction*****\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Num examples = 1000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Num examples = 1000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:  Batch size = 16\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:  Batch size = 16\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NpUNjd0FR0t6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"79AHOV8YdP6r","colab_type":"text"},"source":["#kashgari"]},{"cell_type":"code","metadata":{"id":"RDjV7u-kqCiM","colab_type":"code","outputId":"b990b93d-4a60-4f4f-bcab-079e89510e7f","executionInfo":{"status":"ok","timestamp":1574378702862,"user_tz":-480,"elapsed":22105,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install kashgari"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting kashgari\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/50/4db8af2a78e12e48c557c7c475842bd30f2988bf4e751bf501911d8881f7/kashgari-1.0.0-py3-none-any.whl (75kB)\n","\r\u001b[K     |████▍                           | 10kB 29.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.5MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from kashgari) (0.21.3)\n","Collecting keras-bert>=0.50.0\n","  Downloading https://files.pythonhosted.org/packages/df/fe/bf46de1ef9d1395cd735d8df5402f5d837ef82cfd348a252ad8f32feeaef/keras-bert-0.80.0.tar.gz\n","Collecting numpy==1.16.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from kashgari) (3.6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from kashgari) (2.8.0)\n","Collecting seqeval==0.0.10\n","  Downloading https://files.pythonhosted.org/packages/55/dd/3bf1c646c310daabae47fceb84ea9ab66df7f518a31a89955290d82b8100/seqeval-0.0.10-py3-none-any.whl\n","Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from kashgari) (0.25.3)\n","Collecting keras-gpt-2>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/df/19/d11eac066ffcb61ec9edd23c02e4651eaa31f1f67c167a636dd90b6142a4/keras-gpt-2-0.14.0.tar.gz\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari) (1.3.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari) (0.14.0)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-bert>=0.50.0->kashgari) (2.2.5)\n","Collecting keras-transformer>=0.30.0\n","  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari) (1.12.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari) (1.9.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari) (2.6.1)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 68.6MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert>=0.50.0->kashgari) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert>=0.50.0->kashgari) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert>=0.50.0->kashgari) (1.1.0)\n","Collecting keras-pos-embd>=0.10.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.22.0\n","  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n","Collecting keras-layer-normalization>=0.12.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.7.0\n","  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari) (2.49.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari) (1.10.18)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari) (2.21.0)\n","Collecting keras-self-attention==0.41.0\n","  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (0.9.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (1.13.18)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (0.2.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (2019.9.11)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari) (0.15.2)\n","Building wheels for collected packages: keras-bert, keras-gpt-2, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.80.0-cp36-none-any.whl size=37923 sha256=724798cc50ed6acd268a1802c4580f36a16104af82ea08fc0053af6fc7cb8951\n","  Stored in directory: /root/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0\n","  Building wheel for keras-gpt-2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-gpt-2: filename=keras_gpt_2-0.14.0-cp36-none-any.whl size=10525 sha256=73abf058ce571717f74f9721d469567713b599ef1e3cb6060afc15e4f78480c2\n","  Stored in directory: /root/.cache/pip/wheels/ec/d8/06/ba8216a77a55b8ba4a5c3932c7df93e87eeaea83ced27822aa\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=d6461e6112ee0065ffe18a7efc44d166483ba084e4ee37f67a8855c06f975ec9\n","  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=b85f3e733ef904a978706ebd4b53bd47978fe76c0fd910f118b39b836ee37d0f\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=87d2b2ca7167dd5bc44de8f87c5cbaa26230d22fde51142a0e49dd1d0bc98b77\n","  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=891049acd7082ab574b3810f034f9b07d3dd7e9cfeb64b586bafcc5d356f1e81\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=5ad4338f4d1ed767cbecad8f56ac179b77e564e28430da1449820a9bd02ce334\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=ddda1d934ac91aacef8638b1d42a13aba5e2f37d05e10a6eadd83538ac33fdb1\n","  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=c0233012511e55de271873992b8fbc6f839e5ffcbfbbf1aef827103bad3070d7\n","  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n","Successfully built keras-bert keras-gpt-2 keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, seqeval, regex, keras-gpt-2, kashgari\n","  Found existing installation: numpy 1.17.4\n","    Uninstalling numpy-1.17.4:\n","      Successfully uninstalled numpy-1.17.4\n","Successfully installed kashgari-1.0.0 keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-gpt-2-0.14.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0 numpy-1.16.4 regex-2019.11.1 seqeval-0.0.10\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9Ne4LPWhpYs7","colab_type":"code","outputId":"b76115fc-eeb9-4288-88d1-f8760a9d81df","executionInfo":{"status":"ok","timestamp":1574350015746,"user_tz":-480,"elapsed":5142,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}},"colab":{"base_uri":"https://localhost:8080/","height":508}},"source":["\n","from kashgari.corpus import ChineseDailyNerCorpus\n","\n","train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","\n","def load_data2set(set_x, set_y, max_num = 50000):\n","      \n","      data_set = []\n","      idx = 0\n","      sent_text,sent_slot=\"\",\"\"\n","      for label,ans in zip(set_x,set_y):\n","          idx+=1\n","          if idx > max_num and max_num !=-1:\n","            break\n","          sent_text = \" \".join(label)\n","          sent_slot = \" \".join(ans)\n","          data_set.append([sent_text,sent_slot])\n","          \n","          \n","          \n","      print(\"data_set: \",data_set[:50])\n","      return data_set\n","print(f\"train data count: {len(train_x)}\")\n","print(f\"validate data count: {len(valid_x)}\")\n","print(f\"test data count: {len(test_x)}\")\n","\n","\n","load_data2set(train_x[:10],train_y[:10])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:root:CUDA GPU available, you can set `kashgari.config.use_cudnn_cell = True` to use CuDNNCell. This will speed up the training, but will make model incompatible with CPU device.\n"],"name":"stderr"},{"output_type":"stream","text":["train data count: 20864\n","validate data count: 2318\n","test data count: 4636\n","data_set:  [['门 诊 病 人 可 先 就 诊 后 挂 号 ； 急 诊 病 人 先 抢 救 后 补 交 费 用 ； 将 原 小 洞 式 的 挂 号 、 划 价 、 收 费 、 取 药 窗 口 扩 大 ， 病 人 与 工 作 人 员 可 以 面 对 面 的 解 答 问 题 ， 贴 近 了 患 者 ， 向 开 放 式 医 疗 服 务 迈 了 一 大 步 ， 受 到 群 众 的 好 评 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['近 来 多 次 进 行 反 华 叫 嚣 的 印 度 国 防 部 长 费 尔 南 德 斯 今 天 在 印 度 议 会 上 院 再 次 诬 蔑 中 国 侵 占 印 度 领 土 3 8 0 0 0 平 方 公 里 。', 'O O O O O O O B-LOC O O O B-ORG I-ORG I-ORG I-ORG I-ORG O B-PER I-PER I-PER I-PER I-PER O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O B-LOC I-LOC O O B-LOC I-LOC O O O O O O O O O O O O'], ['用 户 在 该 取 款 机 上 取 钱 时 ， 一 台 摄 像 机 首 先 要 对 用 户 的 眼 睛 进 行 扫 描 ， 然 后 将 扫 描 图 像 转 化 成 数 字 信 息 与 数 据 库 中 的 资 料 核 对 ， 以 对 用 户 的 身 份 进 行 检 验 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['● 人 民 文 学 ： 《 小 冬 与 车 》 作 者 郝 炜 一 九 九 八 年 第 五 期 小 冬 喜 欢 车 ， 小 冬 一 直 想 开 车 ， 小 冬 终 于 开 上 了 做 梦 才 能 开 上 的 黑 色 丰 田 车 。', 'O O O O O O O B-PER I-PER O O O O O B-PER I-PER O O O O O O O O B-PER I-PER O O O O B-PER I-PER O O O O O O B-PER I-PER O O O O O O O O O O O O O O B-ORG I-ORG O O'], ['他 说 ， 祖 国 大 陆 一 贯 主 张 大 力 发 展 两 岸 经 济 交 流 与 合 作 ， 以 促 进 两 岸 经 济 的 共 同 繁 荣 ， 并 为 此 作 出 了 不 懈 努 力 。', 'O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O'], ['一 手 抓 解 决 困 难 ， 一 手 抓 发 展 机 遇 ， 正 确 处 理 两 者 关 系 ， 才 能 变 对 立 为 统 一 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['这 是 枪 案 犯 罪 嫌 疑 人 的 继 母 尤 金 · 斯 泰 恩 在 葬 礼 上 安 慰 失 去 了 孩 子 的 母 亲 苏 姗 · 德 拉 米 妮 。', 'O O O O O O O O O O O O B-PER I-PER I-PER I-PER I-PER I-PER O O O O O O O O O O O O O O B-PER I-PER I-PER I-PER I-PER I-PER I-PER O'], ['流 乞 满 街 ， 饿 殍 遍 地 ， 尤 其 那 些 未 成 年 的 孩 子 更 是 景 况 堪 忧 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['山 西 省 定 襄 县 试 验 班 班 主 任 反 映 ， 学 生 在 饮 用 豆 奶 后 ， 第 三 、 四 节 课 精 力 比 以 前 充 沛 了 。', 'B-LOC I-LOC I-LOC B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'], ['丰 富 的 大 赛 经 验 、 稳 定 的 心 理 素 质 、 超 群 的 防 守 反 攻 能 力 ， 使 王 莲 香 六 度 参 加 尤 伯 杯 、 两 度 带 领 印 尼 队 捧 杯 。', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O B-PER I-PER O O O O O O B-ORG I-ORG I-ORG O O O']]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[['门 诊 病 人 可 先 就 诊 后 挂 号 ； 急 诊 病 人 先 抢 救 后 补 交 费 用 ； 将 原 小 洞 式 的 挂 号 、 划 价 、 收 费 、 取 药 窗 口 扩 大 ， 病 人 与 工 作 人 员 可 以 面 对 面 的 解 答 问 题 ， 贴 近 了 患 者 ， 向 开 放 式 医 疗 服 务 迈 了 一 大 步 ， 受 到 群 众 的 好 评 。',\n","  'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'],\n"," ['近 来 多 次 进 行 反 华 叫 嚣 的 印 度 国 防 部 长 费 尔 南 德 斯 今 天 在 印 度 议 会 上 院 再 次 诬 蔑 中 国 侵 占 印 度 领 土 3 8 0 0 0 平 方 公 里 。',\n","  'O O O O O O O B-LOC O O O B-ORG I-ORG I-ORG I-ORG I-ORG O B-PER I-PER I-PER I-PER I-PER O O O B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O O B-LOC I-LOC O O B-LOC I-LOC O O O O O O O O O O O O'],\n"," ['用 户 在 该 取 款 机 上 取 钱 时 ， 一 台 摄 像 机 首 先 要 对 用 户 的 眼 睛 进 行 扫 描 ， 然 后 将 扫 描 图 像 转 化 成 数 字 信 息 与 数 据 库 中 的 资 料 核 对 ， 以 对 用 户 的 身 份 进 行 检 验 。',\n","  'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'],\n"," ['● 人 民 文 学 ： 《 小 冬 与 车 》 作 者 郝 炜 一 九 九 八 年 第 五 期 小 冬 喜 欢 车 ， 小 冬 一 直 想 开 车 ， 小 冬 终 于 开 上 了 做 梦 才 能 开 上 的 黑 色 丰 田 车 。',\n","  'O O O O O O O B-PER I-PER O O O O O B-PER I-PER O O O O O O O O B-PER I-PER O O O O B-PER I-PER O O O O O O B-PER I-PER O O O O O O O O O O O O O O B-ORG I-ORG O O'],\n"," ['他 说 ， 祖 国 大 陆 一 贯 主 张 大 力 发 展 两 岸 经 济 交 流 与 合 作 ， 以 促 进 两 岸 经 济 的 共 同 繁 荣 ， 并 为 此 作 出 了 不 懈 努 力 。',\n","  'O O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O'],\n"," ['一 手 抓 解 决 困 难 ， 一 手 抓 发 展 机 遇 ， 正 确 处 理 两 者 关 系 ， 才 能 变 对 立 为 统 一 。',\n","  'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'],\n"," ['这 是 枪 案 犯 罪 嫌 疑 人 的 继 母 尤 金 · 斯 泰 恩 在 葬 礼 上 安 慰 失 去 了 孩 子 的 母 亲 苏 姗 · 德 拉 米 妮 。',\n","  'O O O O O O O O O O O O B-PER I-PER I-PER I-PER I-PER I-PER O O O O O O O O O O O O O O B-PER I-PER I-PER I-PER I-PER I-PER I-PER O'],\n"," ['流 乞 满 街 ， 饿 殍 遍 地 ， 尤 其 那 些 未 成 年 的 孩 子 更 是 景 况 堪 忧 。',\n","  'O O O O O O O O O O O O O O O O O O O O O O O O O O O'],\n"," ['山 西 省 定 襄 县 试 验 班 班 主 任 反 映 ， 学 生 在 饮 用 豆 奶 后 ， 第 三 、 四 节 课 精 力 比 以 前 充 沛 了 。',\n","  'B-LOC I-LOC I-LOC B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'],\n"," ['丰 富 的 大 赛 经 验 、 稳 定 的 心 理 素 质 、 超 群 的 防 守 反 攻 能 力 ， 使 王 莲 香 六 度 参 加 尤 伯 杯 、 两 度 带 领 印 尼 队 捧 杯 。',\n","  'O O O O O O O O O O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O B-PER I-PER O O O O O O B-ORG I-ORG I-ORG O O O']]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"N7K1jxPJae5V","colab_type":"text"},"source":["#Data Processor Test"]},{"cell_type":"code","metadata":{"id":"kxqQkOeE-t6J","colab_type":"code","outputId":"a36a6c26-0603-4f07-cbc6-dbd281879eb8","executionInfo":{"status":"ok","timestamp":1574350278897,"user_tz":-480,"elapsed":2409,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["import tokenization\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text, label=None):\n","        \"\"\"Constructs a InputExample.\n","\n","        Args:\n","          guid: Unique id for the example.\n","          text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","          label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text = text\n","        self.label = label\n","        \n","class DataProcessor(object):\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()\n","\n","    @classmethod\n","    def _read_data(cls, input_file):\n","        \"\"\"Reads a BIO data.\"\"\"\n","        with open(input_file) as f:\n","            lines = []\n","            words = []\n","            labels = []\n","            for line in f:\n","                contends = line.strip()\n","                word = line.strip().split(' ')[0]\n","                label = line.strip().split(' ')[-1]\n","                if contends.startswith(\"-DOCSTART-\"):\n","                    words.append('')\n","                    continue\n","                # if len(contends) == 0 and words[-1] == '。':\n","                if len(contends) == 0:\n","                    l = ' '.join([label for label in labels if len(label) > 0])\n","                    w = ' '.join([word for word in words if len(word) > 0])\n","                    lines.append([l, w])\n","                    words = []\n","                    labels = []\n","                    continue\n","                words.append(word)\n","                labels.append(label)\n","            return lines\n","\n","\n","class NerProcessor(DataProcessor):\n","    def get_train_examples(self, data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_train.txt\")), \"train\"\n","        )\n","\n","    def get_dev_examples(self, data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_dev_and_test.txt\")), \"dev\"\n","        )\n","\n","    def get_test_examples(self,data_dir):\n","        return self._create_example(\n","            self._read_data(os.path.join(data_dir, \"for_dev_and_test.txt\")), \"test\")\n","\n","\n","    def get_labels(self):\n","        # prevent potential bug for chinese text mixed with english text\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\",\"[SEP]\"]\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"X\",\"[CLS]\",\"[SEP]\"]\n","        traindata_dir = 'data/'\n","        examples = self.get_train_examples(traindata_dir)\n","        tags = [\"[CLS]\",\"[SEP]\"]\n","        for e in examples:\n","            \n","            for l in e.label.split(\" \"):\n","                if l not in tags:\n","                  tags.append(l)\n","        return tags\n","        #return [\"o\", \"B-CHA\", \"I-CHA\", \"B-TIM\", \"I-TIM\", \"B-MON\", \"I-MON\", \"B-PER\", \"I-PER\",\"[CLS]\",\"[SEP]\"]\n","\n","    def _create_example(self, lines, set_type):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text = tokenization.convert_to_unicode(line[1])\n","            label = tokenization.convert_to_unicode(line[0])\n","            examples.append(InputExample(guid=guid, text=text, label=label))\n","        return examples\n","\n","class kashgariProcessor(DataProcessor):\n","    \"\"\"\n","    from kashgari.corpus import ChineseDailyNerCorpus\n","\n","    train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","    valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","    test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","    \"\"\"\n","    \n","    def get_train_examples(self,*args):\n","        train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n","         \n","        return self._create_example(self.load_data2set(train_x, train_y), \"train\")\n","\n","    def get_dev_examples(self,*args):\n","        valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n","        return self._create_example(self.load_data2set(valid_x, valid_y, max_num = 1000), \"dev\")\n","\n","    def get_test_examples(self,*args):\n","        test_x, test_y  = ChineseDailyNerCorpus.load_data('test')\n","        return self._create_example(self.load_data2set(test_x, test_y, max_num = 1000), \"test\")\n","\n","\n","    def load_data2set(self,set_x, set_y, max_num = 50000):\n","      \n","      data_set = []\n","      idx = 0\n","      sent_text,sent_slot=\"\",\"\"\n","      for label,ans in zip(set_x,set_y):\n","          idx+=1\n","          if idx > max_num and max_num !=-1:\n","            break\n","          sent_text = \" \".join(label)\n","          sent_slot = \" \".join(ans)\n","          data_set.append([sent_text,sent_slot])\n","          \n","      return data_set\n","    def get_labels(self):\n","        # prevent potential bug for chinese text mixed with english text\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\",\"[SEP]\"]\n","        # return [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"X\",\"[CLS]\",\"[SEP]\"]\n","        \n","        examples = self.get_train_examples()\n","        tags = [\"[CLS]\",\"[SEP]\"]\n","        \n","        for idx,e in enumerate(examples):\n","            temp_tags = e.label.split(\" \")\n","            for n_tag in temp_tags:\n","              if n_tag not in tags:\n","                tags.append(n_tag)\n","        return tags\n","\n","    def _create_example(self, lines, set_type):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text = tokenization.convert_to_unicode(line[0])\n","            label = tokenization.convert_to_unicode(line[1])\n","            examples.append(InputExample(guid=guid, text=text, label=label))\n","        return examples\n","a = NerProcessor()\n","b = kashgariProcessor()\n","#print(a.get_train_examples('./data/'))\n","print(\"\\t\",len(a.get_train_examples('./data/')[0].text.split(\" \")),len(a.get_train_examples('./data/')[0].label.split(\" \")))\n","print(\"\\t\",[a.get_train_examples('./data/')[0].text,a.get_train_examples('./data/')[0].label])\n","\n","\n","#print(b.get_train_examples())\n","train_example = b.get_train_examples()[0]\n","train_example_text = train_example.text\n","train_example_label = train_example.label\n","print(\"\\t\",len(train_example_text.split(\" \")),len(train_example_label.split(\" \")))\n","print(\"\\t\",train_example_text,train_example_label)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\t 5 5\n","\t ['支 付 宝 定 额', 'B-CHA I-CHA I-CHA I-CHA I-CHA']\n","\t 47 47\n","\t 据 统 计 ， 委 内 瑞 拉 的 石 油 储 量 高 达 7 3 5 亿 桶 ， 由 于 其 靠 近 美 国 、 加 拿 大 等 工 业 大 国 ， 石 油 市 场 极 其 广 阔 。 O O O O B-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O B-LOC I-LOC O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uHzvvsGOl-C-","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"SdpGFYM1i7cA","colab_type":"code","outputId":"765d5186-226b-4c12-eafd-5fc368569395","executionInfo":{"status":"ok","timestamp":1574350204146,"user_tz":-480,"elapsed":1623,"user":{"displayName":"Theta MGSin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCxEtKLKuZ3_pPd7_CvHcD7rLgyJdcMg_jNDffDIw=s64","userId":"17111648563398166761"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["a = NerProcessor()\n","b = kashgariProcessor()\n","print(b.get_labels(), a.get_labels())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['[CLS]', '[SEP]', 'X', 'O', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER'] ['[CLS]', '[SEP]', 'B-CHA', 'I-CHA', 'B-TIM', 'I-TIM', 'o', 'B-MON', 'I-MON', 'B-PER', 'I-PER']\n"],"name":"stdout"}]}]}